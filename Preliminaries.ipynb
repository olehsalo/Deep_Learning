{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Preliminaries.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR4gKF89zgS7"
      },
      "source": [
        "### Salo Oleh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBS1adVU0Eye"
      },
      "source": [
        "import time\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D8wJMaVzW1s"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DKbBuv0zdfm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5t6jVXuzW1u"
      },
      "source": [
        "## 2.1 Data Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JibwEcQFzW1v",
        "outputId": "9eae3ac3-513e-48bc-f2f8-e321bb652fca"
      },
      "source": [
        "%%time \n",
        "x = torch.arange(12)\n",
        "x\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.12 ms, sys: 23 µs, total: 1.15 ms\n",
            "Wall time: 1.01 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRi58Tc_zW1w",
        "outputId": "1e05f0fe-1500-420d-eab7-f110841b4549"
      },
      "source": [
        "%%time \n",
        "x.shape\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19 µs, sys: 0 ns, total: 19 µs\n",
            "Wall time: 21.9 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpY3_QlSzW1y",
        "outputId": "d4ea4418-1a37-47ff-ab34-ad54a55e96fd"
      },
      "source": [
        "%%time \n",
        "x.numel()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16 µs, sys: 0 ns, total: 16 µs\n",
            "Wall time: 20.5 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQK5nIw6zW1y",
        "outputId": "bc52b5dc-6290-40f1-c833-c56d959945a9"
      },
      "source": [
        "%%time \n",
        "X = x.reshape(3, 4)\n",
        "X\n",
        " "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 396 µs, sys: 0 ns, total: 396 µs\n",
            "Wall time: 318 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjrWpRoEzW10",
        "outputId": "998999b8-4245-4eba-e1a2-a8224592e729"
      },
      "source": [
        "%%time \n",
        "torch.zeros((2, 3, 4))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 365 µs, total: 365 µs\n",
            "Wall time: 5.25 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpht-XCEzW11",
        "outputId": "b459f918-68ff-4e87-a13c-21bfa6f2ed93"
      },
      "source": [
        "\n",
        "%%time \n",
        "torch.ones((2, 3, 4))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 918 µs, sys: 178 µs, total: 1.1 ms\n",
            "Wall time: 8.1 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhG8xCrHzW12",
        "outputId": "e9209ab6-7cf4-4238-f518-9d7313ca23ee"
      },
      "source": [
        "%%time \n",
        "torch.randn(3, 4)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 1.69 ms, total: 1.69 ms\n",
            "Wall time: 5.5 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0856, -0.2393,  0.7348, -0.4992],\n",
              "        [ 0.2966, -1.0686, -1.9670, -1.2256],\n",
              "        [-0.3571, -1.7888,  1.3932,  3.1853]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUle63OfzW13",
        "outputId": "35e8c910-8f62-416a-f58f-394ef88b5b30"
      },
      "source": [
        "%%time \n",
        "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 80 µs, sys: 0 ns, total: 80 µs\n",
            "Wall time: 83.9 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4],\n",
              "        [4, 3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MVvmjFwzW14",
        "outputId": "4f0476a6-2935-4258-ce3a-8247bf80d191"
      },
      "source": [
        "%%time\n",
        "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 90 µs, sys: 0 ns, total: 90 µs\n",
            "Wall time: 96.1 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4],\n",
              "        [4, 3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpfAyM_xzW15",
        "outputId": "5e9c8e46-a97d-4d5f-f2c2-507f7aedb340"
      },
      "source": [
        "%%time\n",
        "x = torch.tensor([1.0, 2, 4, 8])\n",
        "y = torch.tensor([2, 2, 2, 2])\n",
        "x + y, x - y, x * y, x / y, x**y  # The ** operator is exponentiation\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 709 µs, sys: 786 µs, total: 1.5 ms\n",
            "Wall time: 2.49 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD7BVkonzW15",
        "outputId": "3cbe0e99-23ae-4fd7-d5d5-31e512964184"
      },
      "source": [
        "%%time\n",
        "torch.exp(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.05 ms, sys: 1 µs, total: 2.05 ms\n",
            "Wall time: 23.9 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wblFCAqdzW16",
        "outputId": "e2b2b7a8-19da-4f02-8efc-ccffed147862"
      },
      "source": [
        "%%time\n",
        "X = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
        "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 740 µs, sys: 678 µs, total: 1.42 ms\n",
            "Wall time: 10.2 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fONR0pWXzW17",
        "outputId": "1fe26586-fba7-458e-9d16-fe80a4fa2d1e"
      },
      "source": [
        "%%time\n",
        "X == Y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 478 µs, sys: 0 ns, total: 478 µs\n",
            "Wall time: 407 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True, False,  True],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNaqW-oczW17",
        "outputId": "f62d443d-b3db-4317-cb98-88ae909f0e42"
      },
      "source": [
        "%%time\n",
        "X.sum()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 871 µs, sys: 153 µs, total: 1.02 ms\n",
            "Wall time: 1.29 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66.)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCFbBgMyzW18",
        "outputId": "59ce8ec7-5cc7-4be6-9cfb-ad6ef46bef16"
      },
      "source": [
        "%%time\n",
        "a = torch.arange(3).reshape((3, 1))\n",
        "b = torch.arange(2).reshape((1, 2))\n",
        "a, b"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.01 ms, sys: 0 ns, total: 1.01 ms\n",
            "Wall time: 1.08 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UkZCW4VzW18",
        "outputId": "fbd6fbea-f29f-473e-9275-502bfc58b71d"
      },
      "source": [
        "%%time\n",
        "a + b"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 970 µs, sys: 0 ns, total: 970 µs\n",
            "Wall time: 860 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOWHASo4zW19",
        "outputId": "3e434f17-f902-46e4-ccbb-ce15888fbaf4"
      },
      "source": [
        "%%time\n",
        "X[-1], X[1:3]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 105 µs, sys: 19 µs, total: 124 µs\n",
            "Wall time: 128 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8.,  9., 10., 11.]), tensor([[ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONmJTNICzW19",
        "outputId": "0f2ccbf5-ae3f-4ad8-9892-1d39ef4d41fd"
      },
      "source": [
        "%%time\n",
        "X[1, 2] = 9\n",
        "X"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 77 µs, sys: 13 µs, total: 90 µs\n",
            "Wall time: 93.9 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BvRyxzWzW1-",
        "outputId": "d329e10a-b148-4f60-94ab-c33f4e85589c"
      },
      "source": [
        "%%time\n",
        "X[0:2, :] = 12\n",
        "X"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 313 µs, sys: 54 µs, total: 367 µs\n",
            "Wall time: 560 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofIY8YfazW1-",
        "outputId": "1894352e-dda6-4b6a-9a4c-137cc21b65af"
      },
      "source": [
        "%%time\n",
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 89 µs, sys: 0 ns, total: 89 µs\n",
            "Wall time: 94.9 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mkJOGzvzW1_",
        "outputId": "0820a9a7-23a1-4b25-dcd7-5f82144fc647"
      },
      "source": [
        "%%time\n",
        "Z = torch.zeros_like(Y)\n",
        "print('id(Z):', id(Z))\n",
        "Z[:] = X + Y\n",
        "print('id(Z):', id(Z))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id(Z): 139657342450736\n",
            "id(Z): 139657342450736\n",
            "CPU times: user 330 µs, sys: 908 µs, total: 1.24 ms\n",
            "Wall time: 900 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq-seTFWzW1_",
        "outputId": "29503499-fb6f-4ec3-a007-bc466663fb9c"
      },
      "source": [
        "%%time\n",
        "before = id(X)\n",
        "X += Y\n",
        "id(X) == before"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 956 µs, sys: 0 ns, total: 956 µs\n",
            "Wall time: 965 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coSGxxpFzW2A",
        "outputId": "9b81fb75-8a4f-4a6a-8d5d-f7d9368675dd"
      },
      "source": [
        "%%time\n",
        "A = X.numpy()\n",
        "B = torch.from_numpy(A)\n",
        "type(A), type(B)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 49 µs, sys: 5 µs, total: 54 µs\n",
            "Wall time: 58.2 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpqWuvRizW2A",
        "outputId": "46794a6d-10f5-4480-c70e-036ecfad5179"
      },
      "source": [
        "%%time\n",
        "a = torch.tensor([3.5])\n",
        "a, a.item(), float(a), int(a)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.03 ms, sys: 0 ns, total: 1.03 ms\n",
            "Wall time: 953 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMyXuIUYzW2B",
        "outputId": "4cf64b5f-dfce-4a07-89c4-527a7f4e2dc5"
      },
      "source": [
        "#1.Run the code in this section. Change the conditional statement X == Y in this section to X < Y or X > Y, and then see what kind of tensor you can get.\n",
        "%%time\n",
        "x = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
        "y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "x,y,x == y,x < y,x > y"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.22 ms, sys: 0 ns, total: 1.22 ms\n",
            "Wall time: 1.24 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o9GGVPozW2B",
        "outputId": "97149e89-d46e-41b2-be3a-5bbe8fd33459"
      },
      "source": [
        "#2.Replace the two tensors that operate by element in the broadcasting mechanism with other shapes, e.g., 3-dimensional tensors. Is the result the same as expected?\n",
        "%%time\n",
        "a = torch.arange(1, 6, dtype =torch.float32).reshape((5, 1))\n",
        "b = torch.arange(1, 3).reshape((1, 2))\n",
        "print(a, b)\n",
        "print(a + b)\n",
        "print(a - b)\n",
        "print(a * b)\n",
        "print(a / b)\n",
        "print(a // b)\n",
        "print(a % b)\n",
        "print(a ** b)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.]]) tensor([[1, 2]])\n",
            "tensor([[2., 3.],\n",
            "        [3., 4.],\n",
            "        [4., 5.],\n",
            "        [5., 6.],\n",
            "        [6., 7.]])\n",
            "tensor([[ 0., -1.],\n",
            "        [ 1.,  0.],\n",
            "        [ 2.,  1.],\n",
            "        [ 3.,  2.],\n",
            "        [ 4.,  3.]])\n",
            "tensor([[ 1.,  2.],\n",
            "        [ 2.,  4.],\n",
            "        [ 3.,  6.],\n",
            "        [ 4.,  8.],\n",
            "        [ 5., 10.]])\n",
            "tensor([[1.0000, 0.5000],\n",
            "        [2.0000, 1.0000],\n",
            "        [3.0000, 1.5000],\n",
            "        [4.0000, 2.0000],\n",
            "        [5.0000, 2.5000]])\n",
            "tensor([[1., 0.],\n",
            "        [2., 1.],\n",
            "        [3., 1.],\n",
            "        [4., 2.],\n",
            "        [5., 2.]])\n",
            "tensor([[0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 1.]])\n",
            "tensor([[ 1.,  1.],\n",
            "        [ 2.,  4.],\n",
            "        [ 3.,  9.],\n",
            "        [ 4., 16.],\n",
            "        [ 5., 25.]])\n",
            "CPU times: user 10.6 ms, sys: 0 ns, total: 10.6 ms\n",
            "Wall time: 14.7 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiOoeTyBzW2C"
      },
      "source": [
        "## 2.2 Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVRkOipTzW2C",
        "outputId": "587a5c32-561f-42cc-c6c5-85ac78d76dc0"
      },
      "source": [
        "import os\n",
        "\n",
        "%time os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "%time data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
        "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
        "    f.write('2,NA,106000\\n')\n",
        "    f.write('4,NA,178100\\n')\n",
        "    f.write('NA,NA,140000\\n')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 666 µs, sys: 0 ns, total: 666 µs\n",
            "Wall time: 518 µs\n",
            "CPU times: user 11 µs, sys: 0 ns, total: 11 µs\n",
            "Wall time: 13.4 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEmqrQk_zW2D",
        "outputId": "c176d661-5438-4df1-84aa-3f6d2d208e44"
      },
      "source": [
        "%time import pandas as pd\n",
        "\n",
        "%time data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6 µs, sys: 1 µs, total: 7 µs\n",
            "Wall time: 20 µs\n",
            "CPU times: user 3.24 ms, sys: 0 ns, total: 3.24 ms\n",
            "Wall time: 3.14 ms\n",
            "   NumRooms Alley   Price\n",
            "0       NaN  Pave  127500\n",
            "1       2.0   NaN  106000\n",
            "2       4.0   NaN  178100\n",
            "3       NaN   NaN  140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpHRj3f-zW2D",
        "outputId": "9a5014d9-4aed-47b3-b718-8a6083e1370b"
      },
      "source": [
        "%time inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "%time inputs = inputs.fillna(inputs.mean())\n",
        "print(inputs)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 787 µs, sys: 0 ns, total: 787 µs\n",
            "Wall time: 796 µs\n",
            "CPU times: user 3.35 ms, sys: 0 ns, total: 3.35 ms\n",
            "Wall time: 3.32 ms\n",
            "   NumRooms Alley\n",
            "0       3.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0   NaN\n",
            "3       3.0   NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A85ZN8oUzW2D",
        "outputId": "0b5d708f-f28a-475e-96c4-07c4b3568359"
      },
      "source": [
        "%time inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "print(inputs)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.68 ms, sys: 0 ns, total: 5.68 ms\n",
            "Wall time: 7 ms\n",
            "   NumRooms  Alley_Pave  Alley_nan\n",
            "0       3.0           1          0\n",
            "1       2.0           0          1\n",
            "2       4.0           0          1\n",
            "3       3.0           0          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jiatuPezW2E",
        "outputId": "02a97cce-7800-41d2-b3cb-d126c4fe303f"
      },
      "source": [
        "%time import torch\n",
        "\n",
        "%time X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
        "X, y"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
            "Wall time: 9.06 µs\n",
            "CPU times: user 346 µs, sys: 65 µs, total: 411 µs\n",
            "Wall time: 418 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3., 1., 0.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 0., 1.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500, 106000, 178100, 140000]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSR7yzpMzW2F",
        "outputId": "b1824105-ebc1-43c2-b066-24a56db4e772"
      },
      "source": [
        "#1.Delete the column with the most missing values\n",
        "%time import pandas as pd\n",
        "data = pd.read_csv(data_file)\n",
        "data = data.dropna(axis=1, how=any, thresh= len(data) -max(data.isnull().sum(axis=0))+1)\n",
        "print(data)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 8.11 µs\n",
            "   NumRooms   Price\n",
            "0       NaN  127500\n",
            "1       2.0  106000\n",
            "2       4.0  178100\n",
            "3       NaN  140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PEE0p43zW2F",
        "outputId": "87ba049a-c305-45fe-d9fb-f0968ab3832e"
      },
      "source": [
        "#2.Convert the preprocessed dataset to the tensor format.\n",
        "%time inputs1, outputs1 = data.iloc[:, 0:-1], data.iloc[:, -1]\n",
        "%time inputs1 = inputs1.fillna(inputs.mean())\n",
        "%time X, y = torch.tensor(inputs1.values), torch.tensor(outputs1.values)\n",
        "X, y"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 714 µs, sys: 0 ns, total: 714 µs\n",
            "Wall time: 709 µs\n",
            "CPU times: user 2.82 ms, sys: 0 ns, total: 2.82 ms\n",
            "Wall time: 6.4 ms\n",
            "CPU times: user 286 µs, sys: 870 µs, total: 1.16 ms\n",
            "Wall time: 945 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3.],\n",
              "         [2.],\n",
              "         [4.],\n",
              "         [3.]], dtype=torch.float64), tensor([127500, 106000, 178100, 140000]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfDrlYYlzW2G"
      },
      "source": [
        "## 2.3 Linear Algebra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yLD_iqbzW2G",
        "outputId": "4f24f5e1-8e6e-4411-9af2-7f36c18d0191"
      },
      "source": [
        "%time import torch\n",
        "\n",
        "%time x = torch.tensor(3.0)\n",
        "%time y = torch.tensor(2.0)\n",
        "\n",
        "x + y, x * y, x / y, x**y"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8 µs, sys: 1 µs, total: 9 µs\n",
            "Wall time: 12.6 µs\n",
            "CPU times: user 74 µs, sys: 0 ns, total: 74 µs\n",
            "Wall time: 78.4 µs\n",
            "CPU times: user 46 µs, sys: 0 ns, total: 46 µs\n",
            "Wall time: 50.1 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwUaiZSfzW2H",
        "outputId": "b0c18882-0b26-4f2c-a6e8-945bef5d8ebb"
      },
      "source": [
        "%time x = torch.arange(4)\n",
        "x"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 112 µs, sys: 18 µs, total: 130 µs\n",
            "Wall time: 515 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQTrDEQKzW2H",
        "outputId": "4da110fa-9702-4f0d-badf-2baabef7814b"
      },
      "source": [
        "%time x[3]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 44 µs, sys: 8 µs, total: 52 µs\n",
            "Wall time: 57 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a5Vzx5PzW2H",
        "outputId": "292c1bd5-8fb8-4529-df86-4ffbbc308f18"
      },
      "source": [
        "%time len(x)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 38 µs, sys: 0 ns, total: 38 µs\n",
            "Wall time: 42.9 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdtAMuSDzW2I",
        "outputId": "888dd01e-b0b7-46cd-eae2-0f97bf00ef75"
      },
      "source": [
        "%time x.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15 µs, sys: 3 µs, total: 18 µs\n",
            "Wall time: 22.9 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAtJ1cb_zW2I",
        "outputId": "bd1beed4-9ca3-438c-82f3-f8e54640b7fa"
      },
      "source": [
        "%time A = torch.arange(20).reshape(5, 4)\n",
        "A"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 209 µs, sys: 0 ns, total: 209 µs\n",
            "Wall time: 217 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15],\n",
              "        [16, 17, 18, 19]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC10laulzW2I",
        "outputId": "9707a415-f044-43a4-959a-a3aa53b68edf"
      },
      "source": [
        "%time A.T"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 70 µs, sys: 11 µs, total: 81 µs\n",
            "Wall time: 86.3 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  4,  8, 12, 16],\n",
              "        [ 1,  5,  9, 13, 17],\n",
              "        [ 2,  6, 10, 14, 18],\n",
              "        [ 3,  7, 11, 15, 19]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2iEIfjyzW2J",
        "outputId": "20639c38-94a7-4860-a884-bbabaca409fd"
      },
      "source": [
        "%time B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
        "B"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 83 µs, sys: 14 µs, total: 97 µs\n",
            "Wall time: 112 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [2, 0, 4],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F6hH6XLzW2J",
        "outputId": "505d5fbb-9488-491f-b07f-f49ca6618d4d"
      },
      "source": [
        "%time B == B.T"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 96 µs, sys: 15 µs, total: 111 µs\n",
            "Wall time: 117 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zISyAseOzW2K",
        "outputId": "371dc6fb-9fa3-43c7-fa88-a31a4478bc8a"
      },
      "source": [
        "%time X = torch.arange(24).reshape(2, 3, 4)\n",
        "X"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 87 µs, sys: 14 µs, total: 101 µs\n",
            "Wall time: 105 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rZIMmiqzW2K",
        "outputId": "0e0580ea-5075-49b0-c00f-a39e433dd3d5"
      },
      "source": [
        "%time A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
        "%time B = A.clone()  # Assign a copy of `A` to `B` by allocating new memory\n",
        "A, A + B"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 113 µs, sys: 18 µs, total: 131 µs\n",
            "Wall time: 138 µs\n",
            "CPU times: user 2.73 ms, sys: 0 ns, total: 2.73 ms\n",
            "Wall time: 2.87 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[ 0.,  2.,  4.,  6.],\n",
              "         [ 8., 10., 12., 14.],\n",
              "         [16., 18., 20., 22.],\n",
              "         [24., 26., 28., 30.],\n",
              "         [32., 34., 36., 38.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80xsgnYyzW2K",
        "outputId": "7200ef43-394d-4073-b1b1-20fead1e7b8f"
      },
      "source": [
        "%time A * B"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 261 µs, sys: 41 µs, total: 302 µs\n",
            "Wall time: 564 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,   1.,   4.,   9.],\n",
              "        [ 16.,  25.,  36.,  49.],\n",
              "        [ 64.,  81., 100., 121.],\n",
              "        [144., 169., 196., 225.],\n",
              "        [256., 289., 324., 361.]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBXUb8FbzW2L",
        "outputId": "bebd1413-3b01-4671-a70f-c26f73261c7d"
      },
      "source": [
        "%time a = 2\n",
        "%time X = torch.arange(24).reshape(2, 3, 4)\n",
        "a + X, (a * X).shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17 µs, sys: 3 µs, total: 20 µs\n",
            "Wall time: 23.6 µs\n",
            "CPU times: user 480 µs, sys: 0 ns, total: 480 µs\n",
            "Wall time: 339 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 2,  3,  4,  5],\n",
              "          [ 6,  7,  8,  9],\n",
              "          [10, 11, 12, 13]],\n",
              " \n",
              "         [[14, 15, 16, 17],\n",
              "          [18, 19, 20, 21],\n",
              "          [22, 23, 24, 25]]]), torch.Size([2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1u3_ojgzW2L",
        "outputId": "65321296-e856-4dd6-ac01-0b919a5c25cf"
      },
      "source": [
        "%time x = torch.arange(4, dtype=torch.float32)\n",
        "x, x.sum()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 184 µs, sys: 0 ns, total: 184 µs\n",
            "Wall time: 135 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor(6.))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QLcMfd7zW2L",
        "outputId": "c10d6a5f-d4ff-4a21-b7cb-5c2e4fbaadf0"
      },
      "source": [
        "%time A.shape, A.sum()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 66 µs, sys: 10 µs, total: 76 µs\n",
            "Wall time: 82.3 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), tensor(190.))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQp2AidTzW2M",
        "outputId": "7479eb69-5c29-4134-cb91-c5fc3d04917b"
      },
      "source": [
        "%time A_sum_axis0 = A.sum(axis=0)\n",
        "A_sum_axis0, A_sum_axis0.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.15 ms, sys: 0 ns, total: 2.15 ms\n",
            "Wall time: 2.76 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuv4y9N0zW2M",
        "outputId": "5bca86eb-d2ce-4ef8-93f5-3c691f2f6453"
      },
      "source": [
        "%time A_sum_axis1 = A.sum(axis=1)\n",
        "A_sum_axis1, A_sum_axis1.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 102 µs, sys: 0 ns, total: 102 µs\n",
            "Wall time: 108 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvbZWKGnzW2N",
        "outputId": "e49b28a7-68a5-4b80-8f6c-9da974f02507"
      },
      "source": [
        "%time A.sum(axis=[0, 1])  # Same as `A.sum()`"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 99 µs, sys: 16 µs, total: 115 µs\n",
            "Wall time: 121 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(190.)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVjMrsgxzW2N",
        "outputId": "1ec549f2-8165-4aae-b2a8-66f3f31a7eed"
      },
      "source": [
        "%time A.mean(), A.sum() / A.numel()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 992 µs, sys: 715 µs, total: 1.71 ms\n",
            "Wall time: 1.91 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9.5000), tensor(9.5000))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltjcJ-HtzW2N",
        "outputId": "5a22ed5c-d6d5-4bb6-942d-57c698ddc51e"
      },
      "source": [
        "%time A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.55 ms, sys: 0 ns, total: 1.55 ms\n",
            "Wall time: 3.85 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DypTVn4UzW2O",
        "outputId": "c4922c00-c0b5-4424-cbca-dd71ff673541"
      },
      "source": [
        "%time sum_A = A.sum(axis=1, keepdims=True)\n",
        "sum_A"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 76 µs, sys: 12 µs, total: 88 µs\n",
            "Wall time: 95.1 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.],\n",
              "        [22.],\n",
              "        [38.],\n",
              "        [54.],\n",
              "        [70.]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jesYOOO1zW2O",
        "outputId": "ece88e79-a133-4c40-8f20-337d95bfda84"
      },
      "source": [
        "%time A / sum_A"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 59 µs, sys: 10 µs, total: 69 µs\n",
            "Wall time: 73.7 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
              "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
              "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
              "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
              "        [0.2286, 0.2429, 0.2571, 0.2714]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sDDquCWzW2O",
        "outputId": "fac5a5f5-e15b-4772-af03-c4b96fbc5dc8"
      },
      "source": [
        "%time A.cumsum(axis=0)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 262 µs, sys: 42 µs, total: 304 µs\n",
            "Wall time: 2.67 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  6.,  8., 10.],\n",
              "        [12., 15., 18., 21.],\n",
              "        [24., 28., 32., 36.],\n",
              "        [40., 45., 50., 55.]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GfpZyzDzW2P",
        "outputId": "a90216eb-ee2d-4f3a-dccf-6141ee9e8cbf"
      },
      "source": [
        "%time y = torch.ones(4, dtype=torch.float32)\n",
        "x, y, torch.dot(x, y)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 82 µs, sys: 13 µs, total: 95 µs\n",
            "Wall time: 119 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usGKoK5wzW2P",
        "outputId": "d20459e3-b1f5-4572-e288-2df5a460c01f"
      },
      "source": [
        "%time torch.sum(x * y)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 172 µs, sys: 28 µs, total: 200 µs\n",
            "Wall time: 254 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j5LESqyzW2P",
        "outputId": "0b4a92b9-a24b-4d55-e0bd-1ca58488797e"
      },
      "source": [
        "%time A.shape, x.shape, torch.mv(A, x)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 609 µs, total: 609 µs\n",
            "Wall time: 10.7 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bGJbt-_zW2Q",
        "outputId": "248e1dfc-1437-4f2b-af1e-5d2c3cf23c47"
      },
      "source": [
        "%time B = torch.ones(4, 3)\n",
        "torch.mm(A, B)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.31 ms, sys: 44 µs, total: 1.35 ms\n",
            "Wall time: 1.4 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.,  6.,  6.],\n",
              "        [22., 22., 22.],\n",
              "        [38., 38., 38.],\n",
              "        [54., 54., 54.],\n",
              "        [70., 70., 70.]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-d4HfpgzW2Q",
        "outputId": "d162fa02-53cd-4cac-d73e-27b424d1bfd1"
      },
      "source": [
        "%time u = torch.tensor([3.0, -4.0])\n",
        "torch.norm(u)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 67 µs, sys: 11 µs, total: 78 µs\n",
            "Wall time: 83 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXwKaqltzW2R",
        "outputId": "0e88612a-60cb-46ce-a382-64a3a76f2cdf"
      },
      "source": [
        "%time torch.abs(u).sum()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.09 ms, sys: 30 µs, total: 1.12 ms\n",
            "Wall time: 1.72 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29IGr7Z4zW2V",
        "outputId": "8cf71f4e-6f6a-45ea-a8d6-deda89ca6859"
      },
      "source": [
        "%time torch.norm(torch.ones((4, 9)))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.27 ms, sys: 0 ns, total: 1.27 ms\n",
            "Wall time: 1.22 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNqtWQmTzW2V"
      },
      "source": [
        "## 2.4 Calculus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS5sXOjs3SII",
        "outputId": "be36889c-f2c5-4b7b-9d98-a57b66ec9f4b"
      },
      "source": [
        "pip install torch torchvision"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eik-npdv3thw",
        "outputId": "fc22764a-a94f-489b-8b05-3eff2f60f69c"
      },
      "source": [
        "# -U: Upgrade all packages to the newest available version\n",
        "!pip install -U d2l\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l\n",
            "  Downloading d2l-0.17.0-py3-none-any.whl (83 kB)\n",
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 20 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 30 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 83 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l) (3.2.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l) (1.1.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.1.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l) (7.6.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.1.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l) (5.3.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l) (1.15.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l) (3.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l) (4.7.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l) (22.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l) (2.4.7)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l) (4.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l) (21.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l) (2018.9)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l) (1.11.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l) (2021.5.30)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DkaOVt0zW2V"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from IPython import display\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "def f(x):\n",
        "    return 3 * x ** 2 - 4 * x"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrFEGAigzW2W",
        "outputId": "093d3478-da52-4c29-c362-298f38bd1e9c"
      },
      "source": [
        "%time \n",
        "def numerical_lim(f, x, h):\n",
        "    return (f(x + h) - f(x)) / h\n",
        "%time \n",
        "h = 0.1\n",
        "for i in range(5):\n",
        "    print(f'h={h:.5f}, numerical limit={numerical_lim(f, 1, h):.5f}')\n",
        "    h *= 0.1"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 8.11 µs\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "h=0.10000, numerical limit=2.30000\n",
            "h=0.01000, numerical limit=2.03000\n",
            "h=0.00100, numerical limit=2.00300\n",
            "h=0.00010, numerical limit=2.00030\n",
            "h=0.00001, numerical limit=2.00003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9SgNU5szW2W",
        "outputId": "e2e6f9f9-9395-4066-d2a2-e4a7f105e4fb"
      },
      "source": [
        "%time \n",
        "def use_svg_display():  \n",
        "    \"\"\"Use the svg format to display a plot in Jupyter.\"\"\"\n",
        "    display.set_matplotlib_formats('svg')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 7.87 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VuriFAjzW2X",
        "outputId": "10c38fb3-1238-430f-d019-57efe2e12b2c"
      },
      "source": [
        "%time \n",
        "def set_figsize(figsize=(3.5, 2.5)):  \n",
        "    \"\"\"Set the figure size for matplotlib.\"\"\"\n",
        "    use_svg_display()\n",
        "    d2l.plt.rcParams['figure.figsize'] = figsize"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 7.15 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HierrTSVzW2X",
        "outputId": "181cfcc4-ad27-4072-93c5-111e06b61d7c"
      },
      "source": [
        "\n",
        "%time \n",
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "    \"\"\"Set the axes for matplotlib.\"\"\"\n",
        "    axes.set_xlabel(xlabel)\n",
        "    axes.set_ylabel(ylabel)\n",
        "    axes.set_xscale(xscale)\n",
        "    axes.set_yscale(yscale)\n",
        "    axes.set_xlim(xlim)\n",
        "    axes.set_ylim(ylim)\n",
        "    if legend:\n",
        "        axes.legend(legend)\n",
        "    axes.grid()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
            "Wall time: 8.82 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O8GJimIzW2Y",
        "outputId": "57fdfbd1-c6dc-4dc4-d09f-2c74c821a276"
      },
      "source": [
        "\n",
        "%time \n",
        "def plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "         ylim=None, xscale='linear', yscale='linear',\n",
        "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n",
        "    \"\"\"Plot data points.\"\"\"\n",
        "    if legend is None:\n",
        "        legend = []\n",
        "\n",
        "    set_figsize(figsize)\n",
        "    axes = axes if axes else d2l.plt.gca()\n",
        "\n",
        "    # Return True if `X` (tensor or list) has 1 axis\n",
        "    def has_one_axis(X):\n",
        "        return (hasattr(X, \"ndim\") and X.ndim == 1 or\n",
        "                isinstance(X, list) and not hasattr(X[0], \"__len__\"))\n",
        "\n",
        "    if has_one_axis(X):\n",
        "        X = [X]\n",
        "    if Y is None:\n",
        "        X, Y = [[]] * len(X), X\n",
        "    elif has_one_axis(Y):\n",
        "        Y = [Y]\n",
        "    if len(X) != len(Y):\n",
        "        X = X * len(Y)\n",
        "    axes.cla()\n",
        "    for x, y, fmt in zip(X, Y, fmts):\n",
        "        if len(x):\n",
        "            axes.plot(x, y, fmt)\n",
        "        else:\n",
        "            axes.plot(y, fmt)\n",
        "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.72 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "v0Dh11hazW2Y",
        "outputId": "6e696f36-5d4b-4d60-f540-06e20d44845d"
      },
      "source": [
        "%time x = np.arange(0, 3, 0.1)\n",
        "%time plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 30 µs, sys: 5 µs, total: 35 µs\n",
            "Wall time: 38.6 µs\n",
            "CPU times: user 44 ms, sys: 647 µs, total: 44.7 ms\n",
            "Wall time: 50.3 ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 243.529359 180.65625\" width=\"243.529359pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 243.529359 180.65625 \nL 243.529359 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 40.603125 143.1 \nL 235.903125 143.1 \nL 235.903125 7.2 \nL 40.603125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p357e7b935d)\" d=\"M 49.480398 143.1 \nL 49.480398 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m7138cd2564\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.480398\" xlink:href=\"#m7138cd2564\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(46.299148 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p357e7b935d)\" d=\"M 110.702968 143.1 \nL 110.702968 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.702968\" xlink:href=\"#m7138cd2564\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(107.521718 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p357e7b935d)\" d=\"M 171.925539 143.1 \nL 171.925539 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.925539\" xlink:href=\"#m7138cd2564\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(168.744289 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p357e7b935d)\" d=\"M 233.148109 143.1 \nL 233.148109 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"233.148109\" xlink:href=\"#m7138cd2564\" y=\"143.1\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(229.966859 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- x -->\n     <defs>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n     </defs>\n     <g transform=\"translate(135.29375 171.376563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-120\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p357e7b935d)\" d=\"M 40.603125 114.635514 \nL 235.903125 114.635514 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mcf801a2975\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mcf801a2975\" y=\"114.635514\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(27.240625 118.434732)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p357e7b935d)\" d=\"M 40.603125 77.490157 \nL 235.903125 77.490157 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mcf801a2975\" y=\"77.490157\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(27.240625 81.289376)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p357e7b935d)\" d=\"M 40.603125 40.344801 \nL 235.903125 40.344801 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mcf801a2975\" y=\"40.344801\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10 -->\n      <g transform=\"translate(20.878125 44.14402)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- f(x) -->\n     <defs>\n      <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <g transform=\"translate(14.798437 83.771094)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"74.21875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"133.398438\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p357e7b935d)\" d=\"M 49.480398 114.635514 \nL 55.602655 117.38427 \nL 61.724912 119.687282 \nL 67.847169 121.54455 \nL 73.969426 122.956073 \nL 80.091683 123.921853 \nL 86.21394 124.441888 \nL 92.336197 124.516178 \nL 98.458454 124.144725 \nL 104.580711 123.327527 \nL 110.702968 122.064585 \nL 116.825225 120.355898 \nL 122.947482 118.201468 \nL 129.069739 115.601293 \nL 135.191996 112.555374 \nL 141.314254 109.06371 \nL 147.436511 105.126302 \nL 153.558768 100.74315 \nL 159.681025 95.914254 \nL 165.803282 90.639614 \nL 171.925539 84.919229 \nL 178.047796 78.7531 \nL 184.170053 72.141226 \nL 190.29231 65.083608 \nL 196.414567 57.580247 \nL 202.536824 49.63114 \nL 208.659081 41.23629 \nL 214.781338 32.395695 \nL 220.903595 23.109356 \nL 227.025852 13.377273 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p357e7b935d)\" d=\"M 49.480398 136.922727 \nL 55.602655 135.436913 \nL 61.724912 133.951099 \nL 67.847169 132.465285 \nL 73.969426 130.97947 \nL 80.091683 129.493656 \nL 86.21394 128.007842 \nL 92.336197 126.522028 \nL 98.458454 125.036213 \nL 104.580711 123.550399 \nL 110.702968 122.064585 \nL 116.825225 120.578771 \nL 122.947482 119.092956 \nL 129.069739 117.607142 \nL 135.191996 116.121328 \nL 141.314254 114.635514 \nL 147.436511 113.149699 \nL 153.558768 111.663885 \nL 159.681025 110.178071 \nL 165.803282 108.692257 \nL 171.925539 107.206442 \nL 178.047796 105.720628 \nL 184.170053 104.234814 \nL 190.29231 102.749 \nL 196.414567 101.263185 \nL 202.536824 99.777371 \nL 208.659081 98.291557 \nL 214.781338 96.805743 \nL 220.903595 95.319928 \nL 227.025852 93.834114 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 40.603125 143.1 \nL 40.603125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 235.903125 143.1 \nL 235.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 40.603125 143.1 \nL 235.903125 143.1 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 40.603125 7.2 \nL 235.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 47.603125 44.55625 \nL 172.153125 44.55625 \nQ 174.153125 44.55625 174.153125 42.55625 \nL 174.153125 14.2 \nQ 174.153125 12.2 172.153125 12.2 \nL 47.603125 12.2 \nQ 45.603125 12.2 45.603125 14.2 \nL 45.603125 42.55625 \nQ 45.603125 44.55625 47.603125 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 49.603125 20.298437 \nL 69.603125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_10\">\n     <!-- f(x) -->\n     <g transform=\"translate(77.603125 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"35.205078\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"74.21875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"133.398438\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 49.603125 34.976562 \nL 69.603125 34.976562 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_11\">\n     <!-- Tangent line (x=1) -->\n     <defs>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n     </defs>\n     <g transform=\"translate(77.603125 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"44.583984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"105.863281\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"169.242188\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"232.71875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"294.242188\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"357.621094\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"396.830078\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"428.617188\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"456.400391\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"484.183594\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"547.5625\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"609.085938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"640.873047\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"679.886719\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"739.066406\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"822.855469\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"886.478516\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p357e7b935d\">\n   <rect height=\"135.9\" width=\"195.3\" x=\"40.603125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XA5vAllzW2Z"
      },
      "source": [
        "## 2.5 Automatic Differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzLDdUc8zW2Z",
        "outputId": "e77249bc-61ad-42e4-ad31-6326aebb88db"
      },
      "source": [
        "import torch\n",
        "\n",
        "%time x = torch.arange(4.0)\n",
        "x"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 858 µs, sys: 0 ns, total: 858 µs\n",
            "Wall time: 871 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UneuKkIvzW2Z",
        "outputId": "b3578361-8794-437b-cd7c-cfc85283d2c5"
      },
      "source": [
        "%time print(x.requires_grad_(True))  # Same as `x = torch.arange(4.0, requires_grad=True)`\n",
        "%time print(x.grad)  # The default value is None"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2., 3.], requires_grad=True)\n",
            "CPU times: user 1.58 ms, sys: 81 µs, total: 1.66 ms\n",
            "Wall time: 2.09 ms\n",
            "None\n",
            "CPU times: user 501 µs, sys: 0 ns, total: 501 µs\n",
            "Wall time: 509 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym2TEK94zW2a",
        "outputId": "668cf886-d3c5-4dce-b89b-cdd7a5886c7d"
      },
      "source": [
        "%time y = 2 * torch.dot(x, x)\n",
        "y"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 264 µs, sys: 40 µs, total: 304 µs\n",
            "Wall time: 2.69 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0lxii9jzW2a",
        "outputId": "c792f040-0ac7-405e-e274-7b182588b637"
      },
      "source": [
        "%time y.backward()\n",
        "%time x.grad"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 1.6 ms, total: 1.6 ms\n",
            "Wall time: 6.51 ms\n",
            "CPU times: user 0 ns, sys: 21 µs, total: 21 µs\n",
            "Wall time: 23.8 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iqPoiN2zW2a",
        "outputId": "393607fd-a413-423f-d0e8-c3eb3a163fb9"
      },
      "source": [
        "%time x.grad == 4 * x"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 646 µs, sys: 98 µs, total: 744 µs\n",
            "Wall time: 546 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyyxLhg2zW2b",
        "outputId": "92bc0279-7dd5-4242-8cee-f3b679ed8d0e"
      },
      "source": [
        "# PyTorch accumulates the gradient in default, we need to clear the previous\n",
        "# values\n",
        "%time x.grad.zero_()\n",
        "%time y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 916 µs, sys: 612 µs, total: 1.53 ms\n",
            "Wall time: 3.78 ms\n",
            "CPU times: user 600 µs, sys: 91 µs, total: 691 µs\n",
            "Wall time: 522 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obNUDaODzW2b",
        "outputId": "dc7ce1d8-60f2-4007-c60b-4768693dabec"
      },
      "source": [
        "# Invoking `backward` on a non-scalar requires passing in a `gradient` argument\n",
        "# which specifies the gradient of the differentiated function w.r.t `self`.\n",
        "# In our case, we simply want to sum the partial derivatives, so passing\n",
        "# in a gradient of ones is appropriate\n",
        "%time x.grad.zero_()\n",
        "%time y = x * x\n",
        "# y.backward(torch.ones(len(x))) equivalent to the below\n",
        "y.sum().backward()\n",
        "x.grad"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 39 µs, sys: 6 µs, total: 45 µs\n",
            "Wall time: 102 µs\n",
            "CPU times: user 179 µs, sys: 0 ns, total: 179 µs\n",
            "Wall time: 107 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-voymrl0zW2b",
        "outputId": "6f790b88-7637-42ab-c1b9-88c3a827a1ab"
      },
      "source": [
        "%time x.grad.zero_()\n",
        "%time y = x * x\n",
        "%time u = y.detach()\n",
        "%time z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 50 µs, sys: 8 µs, total: 58 µs\n",
            "Wall time: 63.7 µs\n",
            "CPU times: user 73 µs, sys: 11 µs, total: 84 µs\n",
            "Wall time: 88.9 µs\n",
            "CPU times: user 93 µs, sys: 0 ns, total: 93 µs\n",
            "Wall time: 164 µs\n",
            "CPU times: user 69 µs, sys: 0 ns, total: 69 µs\n",
            "Wall time: 74.6 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOpDYF6czW2c",
        "outputId": "9cf4636a-b8b4-4054-d929-f106f186e10d"
      },
      "source": [
        "%time x.grad.zero_()\n",
        "%time y.sum().backward()\n",
        "x.grad == 2 * x"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 46 µs, sys: 7 µs, total: 53 µs\n",
            "Wall time: 57.5 µs\n",
            "CPU times: user 3.24 ms, sys: 0 ns, total: 3.24 ms\n",
            "Wall time: 3.33 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjMGIbHIzW2c"
      },
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQjBAPaQzW2d",
        "outputId": "dfe5c8fa-d60e-4964-d0c4-905174510141"
      },
      "source": [
        "%time a = torch.randn(size=(), requires_grad=True)\n",
        "%time d = f(a)\n",
        "print(d.backward())"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 48 µs, sys: 906 µs, total: 954 µs\n",
            "Wall time: 970 µs\n",
            "CPU times: user 1.92 ms, sys: 133 µs, total: 2.05 ms\n",
            "Wall time: 3.74 ms\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvE7K9d7zW2d",
        "outputId": "52f24fea-d135-4ccd-dc02-2c98658a3918"
      },
      "source": [
        "%time a.grad == d / a\n",
        "a.grad"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 176 µs, sys: 0 ns, total: 176 µs\n",
            "Wall time: 183 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(409600.)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0AGM9CvzW2d"
      },
      "source": [
        "## 2.6 Probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agHg0hNtzW2e"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch.distributions import multinomial\n",
        "from d2l import torch as d2l"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Q98hXgzW2e",
        "outputId": "344068bc-3a72-492a-da37-bc07bde1f647"
      },
      "source": [
        "%time fair_probs = torch.ones([6]) / 6\n",
        "%time multinomial.Multinomial(1, fair_probs).sample()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.08 ms, sys: 5 µs, total: 1.08 ms\n",
            "Wall time: 1.16 ms\n",
            "CPU times: user 783 µs, sys: 1 ms, total: 1.79 ms\n",
            "Wall time: 9.92 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_HYdj1rzW2e",
        "outputId": "782c07cb-f41a-40bf-d7e3-8c061236b9a4"
      },
      "source": [
        "%time multinomial.Multinomial(10, fair_probs).sample()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.63 ms, sys: 0 ns, total: 1.63 ms\n",
            "Wall time: 6.68 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 0., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xerljFenzW2f",
        "outputId": "1d1c0086-a0b6-458d-bb76-599c2eb378c9"
      },
      "source": [
        "# Store the results as 32-bit floats for division\n",
        "%time counts = multinomial.Multinomial(1000, fair_probs).sample()\n",
        "counts / 1000  # Relative frequency as the estimate"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.61 ms, sys: 0 ns, total: 1.61 ms\n",
            "Wall time: 1.68 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1760, 0.1790, 0.1580, 0.1700, 0.1610, 0.1560])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "RnJmouZlzW2f",
        "outputId": "03789cde-305a-439c-ebfc-e33992d66f74"
      },
      "source": [
        "%time counts = multinomial.Multinomial(10, fair_probs).sample((500,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "\n",
        "d2l.set_figsize((6, 4.5))\n",
        "for i in range(6):\n",
        "    d2l.plt.plot(estimates[:, i].numpy(), label=(\"P(die=\" + str(i + 1) + \")\"))\n",
        "d2l.plt.axhline(y=0.167, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Groups of experiments')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.79 ms, sys: 0 ns, total: 1.79 ms\n",
            "Wall time: 5.84 ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x324 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"289.37625pt\" version=\"1.1\" viewBox=\"0 0 392.14375 289.37625\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 289.37625 \nL 392.14375 289.37625 \nL 392.14375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 251.82 \nL 384.94375 251.82 \nL 384.94375 7.2 \nL 50.14375 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0de5a1b195\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m0de5a1b195\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(62.180682 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.356649\" xlink:href=\"#m0de5a1b195\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(116.812899 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"187.351365\" xlink:href=\"#m0de5a1b195\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(177.807615 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.346082\" xlink:href=\"#m0de5a1b195\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(238.802332 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"309.340799\" xlink:href=\"#m0de5a1b195\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(299.797049 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.335515\" xlink:href=\"#m0de5a1b195\" y=\"251.82\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(360.791765 266.418437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Groups of experiments -->\n     <defs>\n      <path d=\"M 59.515625 10.40625 \nL 59.515625 29.984375 \nL 43.40625 29.984375 \nL 43.40625 38.09375 \nL 69.28125 38.09375 \nL 69.28125 6.78125 \nQ 63.578125 2.734375 56.6875 0.65625 \nQ 49.8125 -1.421875 42 -1.421875 \nQ 24.90625 -1.421875 15.25 8.5625 \nQ 5.609375 18.5625 5.609375 36.375 \nQ 5.609375 54.25 15.25 64.234375 \nQ 24.90625 74.21875 42 74.21875 \nQ 49.125 74.21875 55.546875 72.453125 \nQ 61.96875 70.703125 67.390625 67.28125 \nL 67.390625 56.78125 \nQ 61.921875 61.421875 55.765625 63.765625 \nQ 49.609375 66.109375 42.828125 66.109375 \nQ 29.4375 66.109375 22.71875 58.640625 \nQ 16.015625 51.171875 16.015625 36.375 \nQ 16.015625 21.625 22.71875 14.15625 \nQ 29.4375 6.6875 42.828125 6.6875 \nQ 48.046875 6.6875 52.140625 7.59375 \nQ 56.25 8.5 59.515625 10.40625 \nz\n\" id=\"DejaVuSans-71\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     </defs>\n     <g transform=\"translate(160.397656 280.096562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-71\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"116.353516\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"177.535156\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"240.914062\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"304.390625\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"356.490234\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"388.277344\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"449.458984\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"484.664062\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"516.451172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"576.224609\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"635.404297\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"698.880859\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"760.404297\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"801.517578\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"829.300781\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"926.712891\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"988.236328\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1051.615234\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1090.824219\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m20dcd1b1f2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m20dcd1b1f2\" y=\"240.700909\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.00 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(20.878125 244.500128)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m20dcd1b1f2\" y=\"208.932077\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.05 -->\n      <g transform=\"translate(20.878125 212.731296)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m20dcd1b1f2\" y=\"177.163246\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.10 -->\n      <g transform=\"translate(20.878125 180.962464)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m20dcd1b1f2\" y=\"145.394414\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.15 -->\n      <g transform=\"translate(20.878125 149.193633)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m20dcd1b1f2\" y=\"113.625582\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.20 -->\n      <g transform=\"translate(20.878125 117.424801)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m20dcd1b1f2\" y=\"81.856751\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.25 -->\n      <g transform=\"translate(20.878125 85.655969)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m20dcd1b1f2\" y=\"50.087919\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.30 -->\n      <g transform=\"translate(20.878125 53.887138)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m20dcd1b1f2\" y=\"18.319087\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.35 -->\n      <g transform=\"translate(20.878125 22.118306)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Estimated probability -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     </defs>\n     <g transform=\"translate(14.798438 183.033437)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"115.283203\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"154.492188\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"182.275391\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"279.6875\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"340.966797\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"380.175781\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"441.699219\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"505.175781\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"536.962891\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"600.439453\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"639.302734\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"700.484375\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"763.960938\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"825.240234\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"888.716797\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"916.5\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"944.283203\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"972.066406\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1011.275391\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pdf13762a40)\" d=\"M 65.361932 240.700909 \nL 65.971879 177.163245 \nL 67.191773 177.163245 \nL 67.80172 139.04065 \nL 68.411668 134.8048 \nL 69.021615 131.779197 \nL 69.631562 129.51 \nL 70.241509 134.8048 \nL 71.461403 130.954036 \nL 72.071351 124.21519 \nL 73.291245 131.779197 \nL 73.901192 139.04065 \nL 75.121086 136.050637 \nL 75.731034 141.86454 \nL 76.950928 145.39441 \nL 77.560875 149.932814 \nL 78.170822 145.39441 \nL 78.780769 144.013165 \nL 79.390717 145.39441 \nL 80.610611 152.725679 \nL 82.440452 155.253708 \nL 83.660347 148.46882 \nL 84.270294 151.35107 \nL 84.880241 150.207874 \nL 85.490188 151.000674 \nL 86.100135 149.932814 \nL 86.710083 147.15935 \nL 87.32003 146.253031 \nL 87.929977 143.722369 \nL 88.539924 142.950654 \nL 89.759819 144.619561 \nL 91.58966 151.170565 \nL 92.199607 148.92428 \nL 92.809554 149.538176 \nL 94.029449 148.04182 \nL 94.639396 148.636136 \nL 95.249343 145.39441 \nL 97.079185 150.789125 \nL 97.689132 151.277533 \nL 98.299079 150.592951 \nL 98.909026 152.202021 \nL 99.518973 151.52524 \nL 100.12892 149.77632 \nL 100.738868 149.163599 \nL 101.348815 149.63026 \nL 101.958762 151.123217 \nL 103.178656 149.932814 \nL 103.788603 150.35829 \nL 104.398551 151.74818 \nL 105.008498 151.170565 \nL 106.228392 153.803811 \nL 106.838339 154.142353 \nL 107.448286 153.563545 \nL 108.058234 153.895933 \nL 108.668181 153.33662 \nL 109.278128 154.533394 \nL 109.888075 153.121965 \nL 110.498022 154.289682 \nL 111.107969 154.590656 \nL 113.547758 152.5424 \nL 114.157705 153.630777 \nL 114.767652 152.368059 \nL 115.3776 151.901285 \nL 115.987547 152.958417 \nL 117.207441 152.0437 \nL 117.817388 153.062753 \nL 118.427335 153.33662 \nL 119.037283 152.890429 \nL 119.64723 153.8661 \nL 120.257177 154.122111 \nL 122.087018 152.829673 \nL 123.306913 154.66032 \nL 123.91686 152.92723 \nL 124.526807 151.877852 \nL 125.136754 151.491459 \nL 125.746701 152.383558 \nL 126.356649 151.370725 \nL 126.966596 152.246511 \nL 127.576543 151.254687 \nL 128.18649 151.503805 \nL 128.796437 150.537943 \nL 129.406384 150.789125 \nL 130.016332 151.629415 \nL 131.846173 150.592951 \nL 132.45612 150.832326 \nL 133.676015 150.1738 \nL 134.285962 150.410543 \nL 134.895909 147.880667 \nL 136.72575 147.009777 \nL 138.555592 144.606761 \nL 139.165539 143.311209 \nL 139.775486 144.102995 \nL 140.385433 143.85721 \nL 141.605328 142.368807 \nL 142.215275 143.143079 \nL 142.825222 141.9197 \nL 143.435169 141.700368 \nL 144.045116 140.995657 \nL 144.655064 141.271739 \nL 145.265011 140.580955 \nL 146.484905 140.178638 \nL 147.094852 139.511297 \nL 147.704799 139.788146 \nL 148.314747 139.59718 \nL 148.924694 138.027732 \nL 149.534641 138.309277 \nL 150.144588 139.04065 \nL 150.754535 139.311023 \nL 153.194324 138.602459 \nL 154.414218 139.127091 \nL 155.024165 138.954786 \nL 155.634113 137.931936 \nL 156.854007 139.29312 \nL 158.683848 138.793094 \nL 159.293796 139.04065 \nL 159.903743 139.692313 \nL 160.51369 139.930988 \nL 161.733584 139.600096 \nL 162.953479 140.066719 \nL 164.173373 139.742293 \nL 165.393267 138.655574 \nL 167.223109 140.477813 \nL 167.833056 140.694882 \nL 168.443003 140.535652 \nL 169.05295 140.006721 \nL 171.492739 139.403723 \nL 172.102686 138.535237 \nL 172.712633 138.753471 \nL 173.32258 139.32621 \nL 173.932528 138.827671 \nL 174.542475 139.39363 \nL 175.152422 139.602311 \nL 175.762369 138.761358 \nL 176.372316 139.318408 \nL 176.982263 139.178776 \nL 177.592211 139.727542 \nL 178.812105 139.448373 \nL 179.422052 138.635085 \nL 180.031999 138.166587 \nL 180.641946 138.371832 \nL 181.251894 138.242264 \nL 181.861841 138.44498 \nL 183.081735 137.534088 \nL 183.691682 137.411479 \nL 184.301629 136.641781 \nL 184.911577 136.84747 \nL 185.521524 136.409288 \nL 186.131471 135.656225 \nL 186.741418 135.86376 \nL 187.961312 135.643585 \nL 189.181207 136.050637 \nL 189.791154 135.631306 \nL 191.011048 136.032582 \nL 192.230943 135.818163 \nL 192.84089 135.409928 \nL 193.450837 135.306681 \nL 194.060784 134.904705 \nL 195.280678 134.705833 \nL 195.890626 134.312264 \nL 196.500573 134.216487 \nL 197.720467 134.610501 \nL 198.330414 134.514677 \nL 198.940361 134.708531 \nL 199.550309 134.038132 \nL 200.160256 133.659976 \nL 201.38015 134.615699 \nL 202.600044 133.867672 \nL 203.209992 133.778495 \nL 203.819939 133.96878 \nL 205.039833 133.791882 \nL 205.64978 133.429529 \nL 206.259727 133.618034 \nL 206.869675 133.532236 \nL 209.309463 134.268617 \nL 210.529358 134.095876 \nL 212.359199 134.629768 \nL 213.579093 134.457605 \nL 214.189041 134.11324 \nL 214.798988 134.546517 \nL 216.018882 134.3778 \nL 216.628829 134.549632 \nL 217.238776 134.465936 \nL 217.848724 134.889187 \nL 218.458671 135.056939 \nL 219.678565 134.888184 \nL 220.288512 135.053975 \nL 220.898459 134.72207 \nL 221.508407 135.134442 \nL 222.118354 135.051078 \nL 223.338248 135.86376 \nL 223.948195 135.535122 \nL 224.558142 135.451502 \nL 225.16809 135.126925 \nL 226.387984 134.964646 \nL 226.997931 135.362154 \nL 227.607878 135.042775 \nL 228.217825 134.962857 \nL 228.827773 135.119739 \nL 229.43772 135.040124 \nL 230.047667 134.726653 \nL 230.657614 134.882664 \nL 231.267561 134.8048 \nL 232.487456 134.18868 \nL 233.097403 134.114177 \nL 233.70735 133.581459 \nL 234.317297 133.28112 \nL 234.927244 133.21067 \nL 236.757086 133.678249 \nL 237.367033 134.056424 \nL 238.586927 133.913042 \nL 239.196874 134.064272 \nL 239.806822 134.435829 \nL 240.416769 134.14295 \nL 241.026716 134.291813 \nL 241.636663 134.220549 \nL 242.24661 133.713091 \nL 242.856557 133.861897 \nL 243.466505 133.142274 \nL 245.296346 133.588428 \nL 246.51624 133.454448 \nL 247.126188 133.175629 \nL 247.736135 133.322258 \nL 248.956029 132.77104 \nL 250.785871 133.207678 \nL 251.395818 133.143685 \nL 252.005765 132.666183 \nL 252.615712 133.016948 \nL 253.835606 132.072 \nL 255.055501 132.361044 \nL 255.665448 132.707179 \nL 256.275395 132.646415 \nL 256.885342 132.989444 \nL 257.495289 133.129228 \nL 258.105237 132.867271 \nL 258.715184 133.206372 \nL 259.325131 133.344167 \nL 259.935078 133.08399 \nL 260.545025 133.419247 \nL 261.154972 133.160453 \nL 261.76492 133.493399 \nL 262.374867 133.432076 \nL 262.984814 133.762134 \nL 263.594761 133.505461 \nL 264.204708 133.833276 \nL 266.03455 133.071957 \nL 267.864391 132.896763 \nL 268.474338 133.219532 \nL 269.694233 132.724704 \nL 270.30418 132.856563 \nL 270.914127 133.175629 \nL 271.524074 133.305386 \nL 272.134021 132.873757 \nL 272.743969 133.189964 \nL 273.963863 133.075886 \nL 274.57381 133.204052 \nL 275.183757 133.147302 \nL 275.793704 132.907244 \nL 276.403652 133.034786 \nL 277.013599 132.796433 \nL 277.623546 132.923557 \nL 279.453387 132.759082 \nL 280.673282 133.368925 \nL 281.283229 133.313311 \nL 281.893176 133.079531 \nL 282.503123 133.380987 \nL 283.11307 133.325809 \nL 283.723018 133.447915 \nL 284.332965 133.74584 \nL 284.942912 133.690103 \nL 285.552859 133.985718 \nL 286.772753 133.873846 \nL 287.992648 134.1104 \nL 288.602595 133.881458 \nL 289.212542 133.999077 \nL 289.822489 133.94386 \nL 291.042384 134.176845 \nL 292.872225 134.012 \nL 293.482172 134.2965 \nL 294.702067 134.523908 \nL 295.312014 134.468625 \nL 295.921961 134.581274 \nL 296.531908 134.526133 \nL 297.141855 134.638034 \nL 297.751802 134.416704 \nL 298.36175 134.528311 \nL 298.971697 134.47388 \nL 299.581644 134.749792 \nL 300.191591 134.695068 \nL 300.801538 134.8048 \nL 301.411485 134.750218 \nL 302.021433 135.022589 \nL 302.63138 135.130636 \nL 303.241327 134.750635 \nL 303.851274 134.534664 \nL 304.461221 134.481454 \nL 305.071168 134.751051 \nL 306.291063 134.644358 \nL 306.90101 134.431369 \nL 307.510957 134.698372 \nL 308.120904 134.64556 \nL 308.730851 134.434162 \nL 311.17064 134.228142 \nL 311.780587 134.491036 \nL 313.000482 134.388508 \nL 313.610429 134.493346 \nL 314.830323 135.011427 \nL 315.44027 134.495618 \nL 316.050217 134.444965 \nL 316.660165 134.240706 \nL 317.880059 134.753769 \nL 318.490006 134.855718 \nL 319.099953 134.8048 \nL 320.319848 135.006996 \nL 320.929795 134.8048 \nL 321.539742 134.905415 \nL 322.149689 134.704432 \nL 322.759636 134.8048 \nL 323.369583 134.754848 \nL 323.979531 134.555635 \nL 324.589478 134.506506 \nL 325.199425 134.308799 \nL 325.809372 134.408931 \nL 326.419319 134.212378 \nL 327.029266 133.868979 \nL 328.249161 134.069413 \nL 328.859108 134.315672 \nL 330.079002 134.220549 \nL 330.688949 134.464772 \nL 331.908844 134.659743 \nL 332.518791 134.467092 \nL 333.738685 134.660728 \nL 334.348632 134.613133 \nL 335.568527 134.8048 \nL 336.178474 134.61443 \nL 336.788421 134.567366 \nL 337.398368 134.8048 \nL 338.008315 134.899356 \nL 339.22821 134.8048 \nL 339.838157 134.898721 \nL 340.448104 134.851657 \nL 341.058051 134.664544 \nL 341.667998 134.618198 \nL 342.887893 134.8048 \nL 344.107787 134.712318 \nL 345.327681 135.173137 \nL 346.547576 135.354911 \nL 347.157523 135.582442 \nL 347.76747 135.535122 \nL 348.377417 135.35136 \nL 350.817206 135.707967 \nL 351.427153 135.660987 \nL 352.0371 135.884003 \nL 352.647048 135.702229 \nL 353.256995 135.789883 \nL 353.866942 136.011213 \nL 354.476889 135.964091 \nL 355.086836 135.383229 \nL 355.696783 135.470816 \nL 356.306731 135.292196 \nL 356.916678 135.512247 \nL 357.526625 135.33428 \nL 358.136572 135.421242 \nL 358.746519 135.244203 \nL 359.356466 135.462541 \nL 359.966414 135.548699 \nL 360.576361 135.503499 \nL 361.186308 135.327747 \nL 361.796255 135.413649 \nL 362.406202 135.369008 \nL 363.016149 135.584402 \nL 363.626097 135.669262 \nL 364.236044 135.365553 \nL 364.845991 135.579649 \nL 365.455938 135.406245 \nL 366.065885 135.619386 \nL 367.28578 135.5307 \nL 367.895727 135.742316 \nL 369.115621 135.399012 \nL 369.725568 135.35546 \nL 369.725568 135.35546 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pdf13762a40)\" d=\"M 65.361932 113.62558 \nL 65.971879 145.39441 \nL 66.581826 134.8048 \nL 67.191773 129.51 \nL 67.80172 139.04065 \nL 68.411668 145.39441 \nL 69.021615 149.932814 \nL 69.631562 153.33662 \nL 70.241509 155.98402 \nL 70.851456 151.74818 \nL 71.461403 142.506337 \nL 72.071351 145.39441 \nL 72.681298 152.725679 \nL 73.291245 154.471219 \nL 74.511139 165.249935 \nL 75.121086 154.738184 \nL 75.731034 148.92428 \nL 76.340981 140.378287 \nL 76.950928 139.04065 \nL 77.560875 140.856006 \nL 78.780769 138.488144 \nL 79.390717 132.1574 \nL 80.000664 133.957636 \nL 80.610611 133.175629 \nL 81.220558 134.8048 \nL 81.830505 134.048404 \nL 82.440452 137.726077 \nL 83.0504 134.8048 \nL 83.660347 134.1216 \nL 84.270294 137.45221 \nL 85.490188 139.788146 \nL 86.100135 142.671371 \nL 86.710083 141.86454 \nL 87.32003 142.818559 \nL 87.929977 142.050328 \nL 88.539924 142.950654 \nL 89.149871 142.21753 \nL 90.369766 146.907212 \nL 92.199607 148.92428 \nL 92.809554 150.919431 \nL 94.029449 152.01292 \nL 94.639396 151.229503 \nL 95.249343 153.018936 \nL 97.079185 154.385591 \nL 98.909026 152.202021 \nL 99.518973 150.410543 \nL 100.738868 151.317421 \nL 101.348815 152.80714 \nL 101.958762 151.123217 \nL 103.178656 153.966952 \nL 105.618445 155.351804 \nL 107.448286 153.563545 \nL 108.668181 154.21909 \nL 109.888075 153.121965 \nL 110.498022 153.442518 \nL 111.107969 152.918614 \nL 111.717917 153.233477 \nL 112.327864 152.725679 \nL 112.937811 151.426472 \nL 113.547758 151.74818 \nL 114.157705 150.493112 \nL 114.767652 150.043513 \nL 115.987547 150.68922 \nL 116.597494 151.74818 \nL 117.207441 150.566081 \nL 117.817388 150.871798 \nL 119.037283 150.034802 \nL 119.64723 148.92428 \nL 120.257177 149.234598 \nL 120.867124 150.228798 \nL 121.477071 149.83522 \nL 122.696966 150.410543 \nL 123.306913 150.02737 \nL 123.91686 148.997069 \nL 124.526807 149.932814 \nL 125.136754 150.207874 \nL 126.356649 149.48347 \nL 126.966596 147.886083 \nL 127.576543 148.787205 \nL 128.18649 148.449108 \nL 128.796437 147.51234 \nL 129.406384 145.993829 \nL 130.626279 145.39441 \nL 131.236226 146.268785 \nL 131.846173 145.972025 \nL 132.45612 146.253031 \nL 133.066067 145.39441 \nL 133.676015 145.113272 \nL 134.285962 145.39441 \nL 134.895909 144.565661 \nL 135.505856 145.39441 \nL 136.115803 145.122882 \nL 136.72575 144.317509 \nL 137.335698 144.059585 \nL 138.555592 142.506337 \nL 139.165539 143.311209 \nL 139.775486 142.553298 \nL 140.385433 142.32001 \nL 140.995381 142.598753 \nL 142.825222 141.9197 \nL 143.435169 142.192904 \nL 144.045116 142.950654 \nL 144.655064 142.726806 \nL 145.265011 142.987683 \nL 145.874958 142.766921 \nL 146.484905 143.497763 \nL 147.094852 143.27649 \nL 147.704799 142.591283 \nL 148.314747 143.307412 \nL 148.924694 143.552743 \nL 149.534641 142.423229 \nL 150.144588 143.125213 \nL 151.97443 142.506337 \nL 153.804271 143.218471 \nL 154.414218 143.881609 \nL 155.024165 143.247869 \nL 155.634113 143.049063 \nL 156.24406 143.700072 \nL 156.854007 143.921686 \nL 157.463954 143.722369 \nL 158.683848 144.156669 \nL 161.123637 143.383732 \nL 162.343531 143.80597 \nL 162.953479 142.829229 \nL 163.563426 143.041167 \nL 164.173373 142.8607 \nL 164.78332 143.069864 \nL 165.393267 142.891414 \nL 166.613162 143.301854 \nL 167.833056 142.950654 \nL 168.443003 143.525655 \nL 169.05295 143.722369 \nL 169.662897 143.177987 \nL 170.272845 143.374435 \nL 170.882792 142.838299 \nL 171.492739 143.034445 \nL 173.32258 142.538793 \nL 173.932528 142.732221 \nL 174.542475 142.21753 \nL 175.152422 142.059568 \nL 176.372316 141.054414 \nL 176.982263 140.905343 \nL 177.592211 140.414435 \nL 178.202158 140.61201 \nL 178.812105 140.127919 \nL 179.422052 140.324916 \nL 180.031999 140.183656 \nL 181.251894 140.570872 \nL 181.861841 140.43053 \nL 182.471788 140.620862 \nL 183.081735 140.154192 \nL 183.691682 139.366486 \nL 184.301629 139.883497 \nL 184.911577 139.427677 \nL 185.521524 139.297361 \nL 186.131471 139.80693 \nL 186.741418 139.358334 \nL 187.961312 139.103554 \nL 188.57126 138.039065 \nL 189.791154 138.420771 \nL 190.401101 137.991972 \nL 191.620995 138.368612 \nL 194.060784 137.901762 \nL 194.670731 138.086092 \nL 195.280678 137.971786 \nL 195.890626 138.154071 \nL 196.500573 138.040514 \nL 197.11052 137.635204 \nL 197.720467 137.525074 \nL 198.330414 137.996195 \nL 198.940361 137.596613 \nL 199.550309 137.48814 \nL 200.160256 137.666865 \nL 200.770203 137.274129 \nL 201.38015 137.735857 \nL 201.990097 137.346312 \nL 202.600044 137.52249 \nL 203.209992 137.137319 \nL 203.819939 137.312871 \nL 205.039833 136.554393 \nL 205.64978 136.730192 \nL 206.259727 136.630599 \nL 206.869675 137.077255 \nL 208.089569 137.41841 \nL 208.699516 137.317596 \nL 209.309463 136.949533 \nL 209.91941 136.851532 \nL 210.529358 137.286049 \nL 211.749252 137.616979 \nL 212.359199 137.255288 \nL 212.969146 137.419517 \nL 213.579093 137.322008 \nL 214.189041 137.743962 \nL 215.408935 138.063142 \nL 216.018882 138.47701 \nL 217.238776 138.786495 \nL 217.848724 139.192533 \nL 218.458671 139.343204 \nL 219.068618 139.743827 \nL 220.288512 139.538981 \nL 220.898459 139.68595 \nL 221.508407 139.584549 \nL 222.118354 139.730203 \nL 222.728301 139.138775 \nL 223.338248 139.285025 \nL 223.948195 139.18671 \nL 224.558142 139.574173 \nL 225.16809 139.71709 \nL 225.778037 139.377592 \nL 226.997931 139.183965 \nL 227.607878 139.32621 \nL 228.217825 138.993235 \nL 228.827773 139.13513 \nL 229.43772 139.04065 \nL 230.657614 138.386582 \nL 231.267561 138.761358 \nL 231.877508 138.669624 \nL 232.487456 138.809606 \nL 233.097403 138.718355 \nL 234.317297 139.452047 \nL 234.927244 139.58721 \nL 235.537191 139.267566 \nL 236.757086 139.085707 \nL 237.367033 139.220255 \nL 237.97698 139.577581 \nL 238.586927 139.709468 \nL 239.196874 139.173948 \nL 239.806822 139.084922 \nL 241.026716 138.469028 \nL 241.636663 138.383363 \nL 242.24661 138.734971 \nL 242.856557 138.648974 \nL 243.466505 138.997278 \nL 244.076452 138.046516 \nL 245.296346 137.45221 \nL 245.906293 137.585915 \nL 246.51624 137.292298 \nL 247.126188 137.638139 \nL 247.736135 137.558098 \nL 248.346082 137.689682 \nL 248.956029 137.610001 \nL 249.565976 136.901759 \nL 250.175923 136.825192 \nL 252.005765 135.977592 \nL 252.615712 135.492441 \nL 253.225659 135.832923 \nL 253.835606 135.76128 \nL 254.445554 135.485804 \nL 255.665448 135.752115 \nL 256.275395 135.681646 \nL 256.885342 135.813335 \nL 258.105237 135.673352 \nL 259.935078 136.65799 \nL 260.545025 136.586233 \nL 261.154972 136.317602 \nL 261.76492 136.24735 \nL 262.374867 135.981427 \nL 264.204708 136.359241 \nL 265.424603 136.221039 \nL 266.03455 136.345106 \nL 267.254444 136.208248 \nL 267.864391 136.522041 \nL 269.084286 136.764674 \nL 269.694233 137.074007 \nL 270.30418 137.004428 \nL 271.524074 136.49164 \nL 272.134021 136.798142 \nL 273.353916 136.291063 \nL 273.963863 136.224987 \nL 274.57381 135.974581 \nL 275.183757 136.093971 \nL 275.793704 136.396308 \nL 276.403652 135.96447 \nL 277.013599 135.7177 \nL 277.623546 135.654398 \nL 278.233493 135.772992 \nL 278.84344 135.166841 \nL 279.453387 135.105641 \nL 280.063335 134.864798 \nL 280.673282 134.984292 \nL 281.893176 135.5782 \nL 282.503123 135.694683 \nL 283.723018 135.571743 \nL 284.332965 135.15779 \nL 284.942912 135.27415 \nL 286.162806 135.154874 \nL 286.772753 134.92117 \nL 287.382701 134.514677 \nL 287.992648 134.457605 \nL 288.602595 134.573965 \nL 290.432436 133.888947 \nL 291.652331 133.78 \nL 293.482172 134.127073 \nL 294.092119 134.072547 \nL 294.702067 133.681241 \nL 295.921961 133.5754 \nL 297.141855 133.137152 \nL 297.751802 133.086073 \nL 298.36175 132.703468 \nL 298.971697 132.48833 \nL 300.191591 132.7198 \nL 300.801538 132.342099 \nL 301.411485 132.29386 \nL 302.021433 132.082538 \nL 303.241327 132.313127 \nL 303.851274 132.265457 \nL 306.90101 132.830924 \nL 307.510957 132.782666 \nL 308.120904 132.575415 \nL 309.340799 132.797796 \nL 309.950746 133.06621 \nL 311.17064 132.969969 \nL 312.390534 133.187673 \nL 313.610429 133.091782 \nL 314.220376 132.888839 \nL 314.830323 132.84185 \nL 316.660165 133.163795 \nL 317.270112 132.809659 \nL 318.490006 131.801021 \nL 319.7099 132.018062 \nL 320.319848 132.277452 \nL 320.929795 132.384326 \nL 321.539742 132.641605 \nL 322.149689 132.747105 \nL 322.759636 133.00232 \nL 323.369583 133.106467 \nL 323.979531 132.761629 \nL 324.589478 132.86586 \nL 325.199425 133.118406 \nL 325.809372 133.221312 \nL 326.419319 133.175629 \nL 327.029266 133.425694 \nL 327.639214 133.527171 \nL 328.249161 133.4811 \nL 328.859108 133.58198 \nL 329.469055 133.536004 \nL 330.079002 133.198106 \nL 330.688949 133.00748 \nL 331.298897 133.253919 \nL 331.908844 133.354174 \nL 332.518791 133.01977 \nL 333.128738 132.831284 \nL 333.738685 132.787732 \nL 334.348632 132.888129 \nL 335.568527 133.373773 \nL 336.178474 133.329397 \nL 336.788421 133.142757 \nL 337.398368 133.383383 \nL 338.008315 133.197453 \nL 338.618263 133.436876 \nL 339.22821 133.534054 \nL 339.838157 133.349024 \nL 340.448104 133.445956 \nL 341.058051 133.261948 \nL 341.667998 133.358643 \nL 342.277946 133.594563 \nL 344.107787 133.879943 \nL 344.717734 133.697393 \nL 345.327681 133.653756 \nL 345.937629 133.748141 \nL 347.157523 133.661217 \nL 348.377417 133.84832 \nL 348.987365 133.804929 \nL 349.597312 133.897771 \nL 350.207259 133.854455 \nL 350.817206 133.946795 \nL 351.427153 133.903556 \nL 352.0371 133.725607 \nL 353.256995 133.640615 \nL 353.866942 133.464342 \nL 355.086836 133.914917 \nL 355.696783 133.739184 \nL 356.306731 133.830028 \nL 356.916678 134.053138 \nL 357.526625 134.01058 \nL 358.136572 134.232393 \nL 358.746519 134.057815 \nL 359.356466 134.147059 \nL 359.966414 133.842109 \nL 360.576361 133.800432 \nL 361.186308 134.020389 \nL 361.796255 134.10898 \nL 362.406202 133.806605 \nL 365.455938 134.24633 \nL 366.065885 134.204586 \nL 367.28578 133.8654 \nL 368.505674 133.784119 \nL 369.115621 133.871052 \nL 369.725568 134.084713 \nL 369.725568 134.084713 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pdf13762a40)\" d=\"M 65.361932 50.087911 \nL 65.971879 18.319091 \nL 66.581826 71.267131 \nL 67.191773 97.74117 \nL 67.80172 100.91805 \nL 68.411668 81.856751 \nL 69.021615 95.471963 \nL 69.631562 89.79896 \nL 70.241509 85.386621 \nL 70.851456 100.91805 \nL 71.461403 96.297124 \nL 72.071351 108.33078 \nL 73.291245 100.010368 \nL 74.511139 109.65448 \nL 75.121086 106.150562 \nL 76.340981 120.313755 \nL 76.950928 119.97935 \nL 77.560875 113.62558 \nL 78.170822 116.513653 \nL 79.390717 126.8626 \nL 80.000664 128.874622 \nL 80.610611 128.288117 \nL 81.220558 130.098313 \nL 81.830505 127.240793 \nL 83.0504 130.56896 \nL 83.660347 132.072 \nL 84.270294 127.52445 \nL 85.490188 130.444373 \nL 86.100135 129.963841 \nL 86.710083 133.03987 \nL 87.929977 135.362154 \nL 88.539924 133.175629 \nL 89.149871 134.27532 \nL 89.759819 133.771668 \nL 90.369766 131.779197 \nL 90.979713 128.401779 \nL 92.199607 124.92117 \nL 92.809554 126.056867 \nL 93.419502 128.496097 \nL 94.029449 125.53889 \nL 94.639396 123.999077 \nL 95.85929 126.083945 \nL 96.469237 125.844361 \nL 97.079185 126.812648 \nL 98.299079 126.33311 \nL 98.909026 127.240793 \nL 100.12892 126.771301 \nL 100.738868 128.702317 \nL 101.348815 127.39208 \nL 101.958762 129.249596 \nL 103.178656 128.753595 \nL 105.008498 130.954036 \nL 105.618445 130.695403 \nL 107.448286 132.68688 \nL 108.058234 134.208203 \nL 109.278128 131.903539 \nL 109.888075 133.373773 \nL 111.107969 132.854082 \nL 112.327864 130.731873 \nL 112.937811 131.319619 \nL 113.547758 130.30422 \nL 114.767652 129.897424 \nL 115.3776 128.93586 \nL 115.987547 129.51 \nL 116.597494 128.575618 \nL 117.207441 129.879407 \nL 117.817388 127.501623 \nL 118.427335 127.343945 \nL 119.037283 128.617617 \nL 119.64723 129.15701 \nL 120.257177 128.288117 \nL 120.867124 126.74749 \nL 121.477071 127.2896 \nL 122.087018 126.468302 \nL 122.696966 126.33311 \nL 125.136754 128.386857 \nL 125.746701 126.968488 \nL 126.356649 126.836383 \nL 128.796437 128.753595 \nL 129.406384 128.011467 \nL 130.016332 129.064642 \nL 130.626279 128.921687 \nL 131.236226 127.615531 \nL 131.846173 128.065964 \nL 133.676015 127.682591 \nL 134.895909 129.648126 \nL 135.505856 130.057734 \nL 136.72575 129.779228 \nL 138.555592 130.954036 \nL 139.165539 131.853596 \nL 139.775486 132.221971 \nL 140.385433 132.072 \nL 140.995381 132.941035 \nL 141.605328 133.291999 \nL 142.215275 132.636852 \nL 143.435169 134.312264 \nL 144.045116 134.153138 \nL 148.314747 136.35073 \nL 148.924694 137.106889 \nL 150.144588 136.771443 \nL 150.754535 137.057912 \nL 151.364482 137.787788 \nL 151.97443 138.063142 \nL 152.584377 138.77591 \nL 153.804271 139.301764 \nL 154.414218 138.694865 \nL 155.024165 138.954786 \nL 155.634113 139.637645 \nL 156.24406 138.193476 \nL 157.463954 138.706236 \nL 158.073901 138.54231 \nL 158.683848 138.793094 \nL 159.293796 138.63073 \nL 159.903743 138.063142 \nL 160.51369 137.90749 \nL 161.733584 138.401277 \nL 162.343531 139.04065 \nL 162.953479 139.277431 \nL 163.563426 139.903502 \nL 164.173373 140.132094 \nL 164.78332 139.583044 \nL 165.393267 140.195879 \nL 166.003214 139.270302 \nL 166.613162 138.736277 \nL 167.223109 138.965011 \nL 167.833056 138.815069 \nL 168.443003 137.171895 \nL 169.05295 137.405761 \nL 169.662897 138.006316 \nL 170.272845 137.130843 \nL 170.882792 137.360921 \nL 172.102686 138.535237 \nL 172.712633 138.394498 \nL 173.932528 138.827671 \nL 174.542475 138.68766 \nL 175.152422 138.900232 \nL 175.762369 139.459574 \nL 176.372316 138.971203 \nL 176.982263 139.178776 \nL 177.592211 138.697204 \nL 178.812105 138.429055 \nL 180.031999 137.494228 \nL 181.251894 137.244296 \nL 181.861841 137.78313 \nL 182.471788 137.987172 \nL 183.081735 137.8616 \nL 183.691682 138.388978 \nL 184.301629 138.262639 \nL 184.911577 137.492524 \nL 185.521524 138.013776 \nL 186.131471 137.57194 \nL 186.741418 138.087578 \nL 187.351365 138.281991 \nL 189.181207 139.788146 \nL 189.791154 139.970468 \nL 190.401101 140.459455 \nL 191.620995 139.590495 \nL 192.230943 139.770271 \nL 192.84089 139.645769 \nL 194.060784 140.599115 \nL 194.670731 139.875885 \nL 195.280678 139.753219 \nL 195.890626 139.927219 \nL 196.500573 139.21714 \nL 197.720467 138.982356 \nL 198.330414 139.156697 \nL 198.940361 139.04065 \nL 199.550309 139.500645 \nL 200.160256 139.384096 \nL 200.770203 139.553504 \nL 201.38015 139.154103 \nL 203.209992 138.816726 \nL 203.819939 138.984913 \nL 205.039833 138.764397 \nL 205.64978 138.930624 \nL 206.259727 138.273811 \nL 206.869675 138.168027 \nL 207.479622 138.33467 \nL 208.089569 138.770277 \nL 208.699516 138.394498 \nL 210.529358 138.881136 \nL 211.139305 138.51117 \nL 211.749252 138.671546 \nL 212.359199 138.568053 \nL 213.579093 138.884411 \nL 214.189041 138.781307 \nL 214.798988 138.420771 \nL 215.408935 138.320383 \nL 216.018882 137.70841 \nL 216.628829 137.356518 \nL 217.238776 137.769894 \nL 218.458671 138.082541 \nL 219.068618 137.483596 \nL 219.678565 137.139525 \nL 220.288512 136.548977 \nL 221.508407 136.865042 \nL 222.118354 136.528697 \nL 222.728301 136.440267 \nL 223.338248 136.596894 \nL 223.948195 136.265443 \nL 225.778037 136.008164 \nL 226.387984 135.683937 \nL 227.607878 135.518714 \nL 228.217825 134.962857 \nL 228.827773 134.883535 \nL 229.43772 135.040124 \nL 230.047667 134.961105 \nL 230.657614 135.116264 \nL 231.877508 135.886957 \nL 234.317297 136.480856 \nL 234.927244 136.39894 \nL 235.537191 136.544527 \nL 236.147139 135.784628 \nL 237.97698 135.550554 \nL 238.586927 135.02774 \nL 241.026716 135.610931 \nL 241.636663 135.535122 \nL 242.24661 135.241486 \nL 243.466505 135.527642 \nL 244.686399 136.240685 \nL 245.296346 135.949624 \nL 245.906293 135.874459 \nL 246.51624 136.013011 \nL 247.126188 136.363142 \nL 247.736135 136.075556 \nL 249.565976 136.482361 \nL 250.175923 136.407177 \nL 250.785871 136.540806 \nL 252.615712 137.555353 \nL 253.225659 137.477906 \nL 255.055501 137.859498 \nL 255.665448 137.376079 \nL 256.275395 137.502797 \nL 256.885342 137.426997 \nL 257.495289 137.552739 \nL 258.105237 137.878131 \nL 258.715184 137.602057 \nL 259.935078 137.45221 \nL 260.545025 136.982103 \nL 261.154972 137.304218 \nL 261.76492 137.230908 \nL 262.374867 137.550259 \nL 262.984814 137.476646 \nL 264.204708 136.942158 \nL 266.03455 137.307806 \nL 266.644497 136.852346 \nL 267.864391 136.712837 \nL 268.474338 136.073019 \nL 269.694233 135.939408 \nL 270.30418 136.250266 \nL 270.914127 136.183329 \nL 271.524074 135.741937 \nL 272.134021 135.490017 \nL 272.743969 135.425891 \nL 273.353916 135.547932 \nL 274.57381 135.420476 \nL 275.183757 135.541475 \nL 275.793704 135.845402 \nL 276.403652 135.598263 \nL 277.013599 135.7177 \nL 277.623546 135.654398 \nL 278.233493 135.772992 \nL 278.84344 136.071939 \nL 279.453387 136.188668 \nL 280.063335 136.124751 \nL 280.673282 136.420167 \nL 281.283229 136.355956 \nL 282.503123 135.87266 \nL 283.11307 135.987997 \nL 283.723018 135.925708 \nL 284.332965 135.68727 \nL 284.942912 135.97817 \nL 286.162806 135.855012 \nL 287.382701 136.08136 \nL 287.992648 136.367204 \nL 288.602595 136.478366 \nL 289.212542 136.761578 \nL 289.822489 136.354498 \nL 290.432436 136.29307 \nL 291.042384 136.403238 \nL 291.652331 136.342 \nL 292.262278 136.451449 \nL 292.872225 136.730192 \nL 293.482172 136.329711 \nL 294.092119 136.438307 \nL 294.702067 136.377798 \nL 295.312014 136.653786 \nL 295.921961 136.760669 \nL 296.531908 136.69979 \nL 297.751802 136.911633 \nL 298.36175 136.85084 \nL 298.971697 136.95582 \nL 299.581644 136.565158 \nL 300.191591 136.670326 \nL 300.801538 136.939147 \nL 301.411485 136.879055 \nL 302.021433 137.145953 \nL 302.63138 137.248556 \nL 303.241327 137.188142 \nL 305.071168 136.524948 \nL 305.681116 136.788684 \nL 306.291063 136.890634 \nL 306.90101 136.832037 \nL 307.510957 136.614087 \nL 308.730851 136.816832 \nL 309.950746 136.701447 \nL 310.560693 136.486527 \nL 311.780587 136.687397 \nL 312.390534 136.474105 \nL 313.610429 136.673555 \nL 314.830323 137.181013 \nL 316.050217 137.375094 \nL 316.660165 137.625282 \nL 317.270112 137.56731 \nL 317.880059 137.356518 \nL 318.490006 137.45221 \nL 319.7099 137.338207 \nL 320.319848 137.129972 \nL 320.929795 137.225284 \nL 321.539742 137.018308 \nL 322.149689 137.113441 \nL 322.759636 137.057912 \nL 323.979531 137.545648 \nL 324.589478 137.340347 \nL 325.199425 137.284809 \nL 325.809372 137.526428 \nL 326.419319 137.470719 \nL 327.639214 137.654907 \nL 328.249161 137.89344 \nL 328.859108 137.984133 \nL 330.079002 138.456389 \nL 331.298897 138.342756 \nL 331.908844 138.141252 \nL 332.518791 138.230145 \nL 333.128738 138.463035 \nL 333.738685 138.550783 \nL 334.348632 138.206892 \nL 334.95858 138.151411 \nL 335.568527 137.953069 \nL 336.788421 137.843971 \nL 337.398368 137.647655 \nL 338.008315 137.594029 \nL 338.618263 137.399143 \nL 340.448104 137.663059 \nL 341.058051 137.890514 \nL 341.667998 137.977022 \nL 342.277946 137.9235 \nL 342.887893 138.009554 \nL 343.49784 137.817167 \nL 344.717734 137.711752 \nL 345.327681 137.935648 \nL 348.377417 137.67425 \nL 348.987365 137.758987 \nL 350.207259 137.384325 \nL 351.427153 137.823965 \nL 352.647048 137.721438 \nL 353.256995 137.536161 \nL 354.476889 137.43549 \nL 356.306731 138.083592 \nL 357.526625 138.24643 \nL 358.136572 138.195237 \nL 358.746519 138.276083 \nL 359.356466 138.093505 \nL 359.966414 138.3055 \nL 360.576361 137.992606 \nL 361.186308 137.942465 \nL 362.406202 138.363604 \nL 363.016149 138.313017 \nL 363.626097 138.003295 \nL 364.236044 137.565436 \nL 365.455938 137.726077 \nL 366.675832 137.6287 \nL 367.28578 137.70841 \nL 368.505674 137.611686 \nL 369.115621 137.818284 \nL 369.725568 137.896972 \nL 369.725568 137.896972 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#pdf13762a40)\" d=\"M 65.361932 177.163245 \nL 65.971879 208.932077 \nL 66.581826 134.8048 \nL 67.191773 161.27883 \nL 67.80172 177.163245 \nL 68.411668 166.573635 \nL 69.021615 159.009623 \nL 69.631562 145.39441 \nL 70.241509 134.8048 \nL 70.851456 113.62558 \nL 71.461403 125.177881 \nL 72.071351 118.92039 \nL 72.681298 118.513093 \nL 73.291245 113.62558 \nL 73.901192 113.62558 \nL 75.121086 121.100599 \nL 75.731034 113.62558 \nL 76.950928 119.97935 \nL 78.780769 119.150601 \nL 79.390717 116.27298 \nL 80.000664 118.708594 \nL 80.610611 116.069336 \nL 81.220558 111.272337 \nL 81.830505 113.62558 \nL 82.440452 113.62558 \nL 83.0504 117.86143 \nL 83.660347 119.77439 \nL 84.270294 123.55334 \nL 84.880241 125.177881 \nL 86.100135 124.517754 \nL 86.710083 125.98013 \nL 87.32003 125.646218 \nL 88.539924 128.288117 \nL 89.149871 124.74467 \nL 89.759819 122.923776 \nL 90.369766 124.21519 \nL 91.58966 123.733845 \nL 92.199607 126.33311 \nL 92.809554 126.056867 \nL 93.419502 124.440506 \nL 94.029449 125.53889 \nL 94.639396 127.889142 \nL 95.249343 128.874622 \nL 95.85929 128.575618 \nL 96.469237 127.066244 \nL 97.689132 121.861947 \nL 98.299079 121.712194 \nL 98.909026 119.298583 \nL 99.518973 120.313755 \nL 100.12892 120.198446 \nL 100.738868 117.933225 \nL 101.348815 118.92039 \nL 101.958762 120.91679 \nL 102.568709 119.77439 \nL 103.788603 119.58224 \nL 104.398551 118.513093 \nL 105.008498 119.401736 \nL 105.618445 118.367203 \nL 107.448286 118.163985 \nL 108.668181 119.80285 \nL 109.888075 117.918663 \nL 110.498022 118.708594 \nL 111.717917 118.576565 \nL 112.327864 120.142263 \nL 112.937811 120.864054 \nL 114.157705 120.68532 \nL 114.767652 119.82438 \nL 115.3776 119.749698 \nL 115.987547 118.163985 \nL 116.597494 118.110595 \nL 117.207441 117.319632 \nL 118.427335 117.235681 \nL 119.037283 115.767303 \nL 119.64723 115.7435 \nL 120.257177 115.022012 \nL 121.477071 114.99198 \nL 122.696966 116.300854 \nL 123.306913 114.94928 \nL 123.91686 116.245694 \nL 124.526807 115.570608 \nL 125.136754 114.267377 \nL 125.746701 113.62558 \nL 126.356649 114.883753 \nL 126.966596 115.494335 \nL 127.576543 114.859326 \nL 128.18649 113.014639 \nL 129.406384 114.22499 \nL 130.016332 113.031776 \nL 130.626279 113.037267 \nL 131.236226 114.208497 \nL 131.846173 114.78081 \nL 132.45612 114.197997 \nL 133.066067 115.327483 \nL 134.285962 115.297622 \nL 134.895909 116.388091 \nL 135.505856 116.912013 \nL 136.72575 119.010126 \nL 137.335698 119.498809 \nL 137.945645 120.50883 \nL 138.555592 120.451947 \nL 139.775486 119.307814 \nL 140.385433 119.77439 \nL 140.995381 118.708594 \nL 141.605328 119.172519 \nL 142.215275 119.128844 \nL 142.825222 119.58224 \nL 143.435169 118.058446 \nL 144.045116 119.001842 \nL 144.655064 118.960808 \nL 145.265011 119.401736 \nL 145.874958 120.313755 \nL 147.094852 119.27337 \nL 147.704799 120.166227 \nL 148.314747 120.11848 \nL 148.924694 119.611013 \nL 149.534641 120.025061 \nL 150.754535 119.934283 \nL 151.364482 120.784752 \nL 151.97443 120.734695 \nL 153.194324 119.760255 \nL 153.804271 118.847857 \nL 154.414218 118.380098 \nL 155.024165 118.347973 \nL 155.634113 118.742707 \nL 156.24406 119.555768 \nL 156.854007 119.095716 \nL 157.463954 119.059728 \nL 159.293796 117.72479 \nL 160.51369 117.672565 \nL 161.123637 116.84268 \nL 161.733584 117.621666 \nL 162.343531 117.59669 \nL 162.953479 117.966665 \nL 163.563426 117.547656 \nL 164.173373 117.523598 \nL 164.78332 118.274683 \nL 166.003214 117.453148 \nL 167.223109 118.163985 \nL 167.833056 118.137134 \nL 168.443003 118.484348 \nL 169.05295 118.084369 \nL 169.662897 118.797251 \nL 170.272845 118.767361 \nL 170.882792 118.372647 \nL 171.492739 118.345521 \nL 172.102686 119.040726 \nL 172.712633 119.010126 \nL 173.32258 118.622929 \nL 173.932528 118.595008 \nL 174.542475 118.92039 \nL 175.152422 118.189065 \nL 175.762369 118.163985 \nL 176.372316 118.833589 \nL 177.592211 119.464176 \nL 178.202158 119.09119 \nL 178.812105 119.401736 \nL 179.422052 120.046941 \nL 180.031999 120.349145 \nL 180.641946 120.313755 \nL 181.251894 119.94608 \nL 182.471788 119.880582 \nL 183.691682 120.468099 \nL 184.301629 120.433191 \nL 184.911577 120.721156 \nL 185.521524 120.364426 \nL 186.131471 120.649844 \nL 186.741418 119.97935 \nL 187.351365 120.26385 \nL 187.961312 119.916436 \nL 189.181207 120.477681 \nL 189.791154 121.064138 \nL 190.401101 120.719594 \nL 191.011048 120.992268 \nL 191.620995 120.956849 \nL 192.230943 121.225783 \nL 194.060784 121.118228 \nL 194.670731 121.381349 \nL 195.280678 121.048204 \nL 196.500573 121.56779 \nL 197.11052 121.238394 \nL 198.330414 121.749118 \nL 198.940361 121.712194 \nL 199.550309 121.963101 \nL 201.38015 121.851437 \nL 202.600044 122.340925 \nL 203.819939 122.264472 \nL 205.64978 122.977449 \nL 207.479622 122.857548 \nL 208.089569 122.547893 \nL 208.699516 122.510087 \nL 210.529358 121.601022 \nL 211.139305 121.56779 \nL 212.359199 122.027255 \nL 212.969146 121.208268 \nL 213.579093 120.656387 \nL 214.189041 120.368356 \nL 214.798988 120.340946 \nL 215.408935 120.056523 \nL 216.628829 120.515211 \nL 217.238776 120.487651 \nL 217.848724 119.954033 \nL 218.458671 119.928924 \nL 220.288512 120.602268 \nL 220.898459 121.0714 \nL 222.728301 120.985158 \nL 223.948195 121.415642 \nL 224.558142 121.385903 \nL 225.16809 121.597993 \nL 226.387984 122.49688 \nL 226.997931 122.463524 \nL 227.607878 122.668399 \nL 228.217825 123.108815 \nL 229.43772 123.038573 \nL 230.047667 123.47275 \nL 230.657614 123.670136 \nL 231.267561 123.633344 \nL 231.877508 124.060599 \nL 233.097403 123.98498 \nL 234.317297 124.367566 \nL 234.927244 124.32906 \nL 235.537191 124.063913 \nL 236.147139 124.478993 \nL 236.757086 124.665813 \nL 237.367033 124.402284 \nL 237.97698 124.364347 \nL 239.196874 124.733565 \nL 239.806822 124.69486 \nL 240.416769 124.87704 \nL 241.026716 125.277814 \nL 241.636663 125.456738 \nL 242.24661 125.852759 \nL 244.076452 125.727992 \nL 244.686399 125.471583 \nL 245.296346 125.860873 \nL 250.175923 127.210941 \nL 250.785871 127.166395 \nL 251.395818 126.706863 \nL 252.005765 126.871216 \nL 252.615712 126.828213 \nL 254.445554 127.313762 \nL 255.055501 127.066244 \nL 255.665448 127.023298 \nL 256.885342 126.534823 \nL 257.495289 126.695038 \nL 258.105237 126.252937 \nL 258.715184 126.013428 \nL 259.325131 126.372951 \nL 259.935078 126.13456 \nL 260.545025 126.293525 \nL 262.374867 126.176228 \nL 262.984814 125.942117 \nL 263.594761 126.099236 \nL 264.204708 126.06109 \nL 264.814655 126.410595 \nL 266.03455 126.718196 \nL 266.644497 127.062551 \nL 267.864391 127.363459 \nL 268.474338 126.941855 \nL 269.084286 126.71244 \nL 269.694233 126.673499 \nL 270.30418 126.257699 \nL 270.914127 126.596288 \nL 271.524074 126.745454 \nL 272.743969 126.668509 \nL 273.353916 126.816151 \nL 274.57381 126.739461 \nL 275.183757 126.33311 \nL 275.793704 126.112756 \nL 277.013599 126.771301 \nL 277.623546 126.733638 \nL 278.84344 127.020988 \nL 279.453387 126.982936 \nL 280.063335 127.30508 \nL 280.673282 127.445924 \nL 281.283229 127.764952 \nL 281.893176 127.903713 \nL 282.503123 128.219665 \nL 283.11307 128.001421 \nL 283.723018 127.961382 \nL 284.332965 128.27454 \nL 287.992648 129.075994 \nL 288.602595 129.0339 \nL 289.212542 128.819368 \nL 289.822489 129.122576 \nL 290.432436 129.08069 \nL 291.652331 129.3392 \nL 293.482172 129.213486 \nL 294.092119 129.003044 \nL 294.702067 129.130794 \nL 295.921961 129.048973 \nL 296.531908 129.342798 \nL 297.751802 129.593166 \nL 298.36175 129.551469 \nL 299.581644 129.798807 \nL 300.191591 129.592304 \nL 300.801538 129.551043 \nL 301.411485 129.673756 \nL 302.021433 129.305826 \nL 302.63138 129.265625 \nL 305.681116 129.871918 \nL 306.291063 129.349548 \nL 306.90101 129.469989 \nL 307.510957 129.749461 \nL 308.120904 129.868292 \nL 308.730851 129.668842 \nL 309.340799 129.628831 \nL 309.950746 129.747075 \nL 310.560693 129.707073 \nL 311.780587 129.000128 \nL 312.390534 129.11876 \nL 314.220376 129.005117 \nL 314.830323 128.812636 \nL 315.44027 128.930274 \nL 316.050217 128.73891 \nL 316.660165 128.702317 \nL 318.490006 129.051794 \nL 319.099953 128.862427 \nL 319.7099 128.521973 \nL 320.929795 128.45104 \nL 321.539742 128.566747 \nL 322.149689 128.832462 \nL 322.759636 128.796512 \nL 323.369583 128.610876 \nL 323.979531 128.575618 \nL 325.199425 129.1008 \nL 325.809372 128.916186 \nL 326.419319 128.880549 \nL 327.029266 129.140593 \nL 327.639214 128.957172 \nL 328.859108 128.886362 \nL 329.469055 128.9976 \nL 330.079002 129.254387 \nL 330.688949 129.218542 \nL 331.298897 129.03746 \nL 331.908844 129.147343 \nL 332.518791 129.401451 \nL 333.128738 129.51 \nL 333.738685 129.762129 \nL 334.348632 129.725621 \nL 334.95858 129.545855 \nL 335.568527 129.51 \nL 336.788421 129.723689 \nL 338.008315 129.651819 \nL 338.618263 129.757641 \nL 339.22821 129.721786 \nL 339.838157 129.826984 \nL 340.448104 129.791138 \nL 342.277946 130.103483 \nL 342.887893 129.928006 \nL 343.49784 130.170401 \nL 344.107787 130.134272 \nL 344.717734 130.236733 \nL 345.327681 130.062496 \nL 345.937629 130.02684 \nL 347.157523 130.230456 \nL 347.76747 130.194668 \nL 348.377417 130.29568 \nL 349.597312 130.224283 \nL 350.207259 130.324585 \nL 350.817206 129.88255 \nL 351.427153 129.847964 \nL 352.0371 130.083326 \nL 352.647048 129.913842 \nL 353.256995 130.013737 \nL 353.866942 129.97916 \nL 354.476889 129.54344 \nL 355.696783 129.210295 \nL 356.306731 129.177688 \nL 356.916678 128.879924 \nL 357.526625 129.11289 \nL 358.136572 128.948594 \nL 358.746519 129.180443 \nL 359.356466 129.279789 \nL 359.966414 128.984894 \nL 360.576361 129.084231 \nL 361.186308 129.313892 \nL 361.796255 129.020749 \nL 362.406202 129.119394 \nL 363.626097 129.056159 \nL 364.236044 129.283539 \nL 364.845991 129.251717 \nL 365.455938 129.477781 \nL 366.065885 129.445685 \nL 366.675832 129.542087 \nL 367.28578 129.51 \nL 367.895727 129.605881 \nL 368.505674 129.446206 \nL 369.115621 129.541831 \nL 369.725568 129.255845 \nL 369.725568 129.255845 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#pdf13762a40)\" d=\"M 65.361932 113.62558 \nL 65.971879 177.163245 \nL 66.581826 177.163245 \nL 67.191773 129.51 \nL 67.80172 139.04065 \nL 68.411668 155.98402 \nL 69.021615 140.856006 \nL 69.631562 153.33662 \nL 70.241509 155.98402 \nL 71.461403 159.834793 \nL 72.681298 152.725679 \nL 73.291245 154.471219 \nL 74.511139 141.42331 \nL 75.121086 147.263165 \nL 75.731034 148.92428 \nL 76.340981 147.066461 \nL 77.560875 149.932814 \nL 78.170822 148.282492 \nL 79.390717 155.98402 \nL 80.000664 151.74818 \nL 80.610611 155.169435 \nL 81.220558 155.98402 \nL 81.830505 154.471219 \nL 82.440452 155.253708 \nL 83.0504 153.8661 \nL 83.660347 154.61762 \nL 84.270294 149.36552 \nL 86.100135 140.856006 \nL 86.710083 141.86454 \nL 88.539924 139.692313 \nL 89.149871 142.21753 \nL 89.759819 141.520166 \nL 90.369766 137.830403 \nL 90.979713 140.222739 \nL 91.58966 138.174228 \nL 92.199607 137.6287 \nL 93.419502 133.903556 \nL 94.029449 136.1285 \nL 94.639396 135.669262 \nL 95.249343 132.68688 \nL 96.469237 129.51 \nL 97.079185 129.210295 \nL 97.689132 130.098313 \nL 98.299079 132.109266 \nL 98.909026 131.779197 \nL 99.518973 132.575415 \nL 100.738868 136.240685 \nL 101.348815 136.92273 \nL 101.958762 134.457605 \nL 102.568709 134.1216 \nL 103.178656 134.8048 \nL 103.788603 132.48833 \nL 104.398551 133.175629 \nL 105.618445 132.59205 \nL 106.838339 130.200623 \nL 107.448286 129.963841 \nL 108.058234 127.943932 \nL 108.668181 128.62753 \nL 109.278128 130.16278 \nL 109.888075 129.93931 \nL 110.498022 128.874622 \nL 111.107969 129.51 \nL 111.717917 129.303705 \nL 112.327864 129.917288 \nL 112.937811 128.906794 \nL 114.157705 130.098313 \nL 114.767652 131.447122 \nL 115.3776 131.232401 \nL 115.987547 130.266396 \nL 116.597494 130.070629 \nL 117.207441 131.357026 \nL 118.427335 130.954036 \nL 119.037283 132.187148 \nL 119.64723 131.98091 \nL 120.257177 132.477413 \nL 121.477071 134.8048 \nL 122.087018 134.579494 \nL 123.306913 132.81925 \nL 123.91686 133.931429 \nL 124.526807 133.724235 \nL 125.136754 134.8048 \nL 126.356649 135.643585 \nL 127.576543 135.216046 \nL 129.406384 136.403238 \nL 130.016332 136.190363 \nL 130.626279 137.158053 \nL 131.846173 136.730192 \nL 132.45612 137.094448 \nL 133.676015 136.679075 \nL 134.285962 135.919498 \nL 134.895909 136.27814 \nL 137.945645 135.33428 \nL 139.165539 137.061604 \nL 139.775486 137.387639 \nL 140.385433 136.68361 \nL 142.825222 137.94859 \nL 144.045116 137.574392 \nL 144.655064 137.876597 \nL 145.265011 138.655574 \nL 146.484905 137.333663 \nL 147.094852 137.6287 \nL 147.704799 136.517828 \nL 148.314747 135.886957 \nL 148.924694 136.646477 \nL 149.534641 136.937964 \nL 150.144588 135.86376 \nL 150.754535 135.706045 \nL 151.97443 134.508589 \nL 153.194324 134.220549 \nL 153.804271 134.514677 \nL 154.414218 134.372574 \nL 155.634113 134.946951 \nL 156.24406 133.957636 \nL 156.854007 133.402205 \nL 158.073901 133.974243 \nL 158.683848 134.66728 \nL 159.903743 135.212098 \nL 160.51369 135.074606 \nL 161.123637 135.743121 \nL 161.733584 135.20441 \nL 162.343531 135.06954 \nL 163.563426 135.589221 \nL 164.173373 136.234076 \nL 164.78332 136.096215 \nL 166.003214 136.591005 \nL 166.613162 135.692553 \nL 167.223109 135.183003 \nL 169.05295 135.919498 \nL 169.662897 135.789883 \nL 170.272845 136.396308 \nL 170.882792 136.630599 \nL 171.492739 135.772992 \nL 172.102686 135.647155 \nL 172.712633 135.881711 \nL 173.32258 135.042775 \nL 175.152422 134.687787 \nL 175.762369 135.270278 \nL 176.982263 135.725643 \nL 177.592211 135.606178 \nL 178.202158 135.8296 \nL 179.422052 135.593387 \nL 180.031999 136.149519 \nL 180.641946 135.696558 \nL 181.251894 135.913665 \nL 181.861841 136.45943 \nL 182.471788 136.670326 \nL 183.081735 137.206566 \nL 184.301629 136.965951 \nL 185.521524 138.013776 \nL 186.131471 138.210509 \nL 186.741418 138.722956 \nL 187.351365 138.598094 \nL 188.57126 138.978048 \nL 189.181207 138.230855 \nL 189.791154 138.420771 \nL 191.011048 137.56731 \nL 191.620995 137.757671 \nL 192.230943 137.338207 \nL 194.060784 137.901762 \nL 194.670731 137.787788 \nL 195.280678 138.268698 \nL 195.890626 137.858551 \nL 197.11052 138.806406 \nL 198.330414 137.996195 \nL 199.550309 138.350642 \nL 200.160256 138.811679 \nL 201.38015 138.586809 \nL 201.990097 139.04065 \nL 202.600044 138.647052 \nL 203.209992 138.816726 \nL 203.819939 138.148892 \nL 204.429886 138.041801 \nL 205.64978 138.380514 \nL 206.259727 138.821554 \nL 206.869675 138.986106 \nL 207.479622 138.606199 \nL 208.089569 138.499903 \nL 208.699516 138.932953 \nL 209.91941 138.720286 \nL 210.529358 138.34944 \nL 211.139305 138.51117 \nL 211.749252 138.144262 \nL 212.359199 138.3055 \nL 213.579093 139.144806 \nL 216.018882 138.73321 \nL 216.628829 138.3772 \nL 217.238776 137.769894 \nL 218.458671 137.074007 \nL 219.068618 137.232461 \nL 219.678565 137.639815 \nL 220.288512 137.545648 \nL 220.898459 137.20401 \nL 221.508407 137.606725 \nL 222.728301 137.912177 \nL 223.338248 137.085643 \nL 223.948195 137.482639 \nL 225.778037 137.211537 \nL 226.387984 136.882766 \nL 227.607878 136.708558 \nL 228.217825 136.859503 \nL 228.827773 136.773128 \nL 229.43772 136.452074 \nL 230.047667 136.6023 \nL 230.657614 136.517828 \nL 231.267561 136.201232 \nL 231.877508 135.65506 \nL 233.097403 135.495433 \nL 233.70735 135.645858 \nL 234.317297 135.56665 \nL 234.927244 135.94347 \nL 236.147139 136.23685 \nL 237.367033 136.077052 \nL 237.97698 135.77427 \nL 239.196874 135.619386 \nL 240.416769 135.90789 \nL 241.026716 135.830784 \nL 241.636663 135.973313 \nL 242.24661 135.896519 \nL 242.856557 136.037836 \nL 243.466505 136.395049 \nL 244.076452 136.533715 \nL 244.686399 136.456069 \nL 246.51624 136.865866 \nL 247.126188 136.363142 \nL 248.346082 136.212064 \nL 249.565976 136.482361 \nL 250.175923 136.407177 \nL 251.395818 137.088834 \nL 252.005765 137.219376 \nL 253.835606 136.99105 \nL 254.445554 136.711616 \nL 255.665448 136.970088 \nL 256.275395 137.30044 \nL 257.495289 137.150602 \nL 258.715184 137.402257 \nL 259.325131 136.929367 \nL 259.935078 137.25365 \nL 260.545025 137.180047 \nL 261.154972 137.304218 \nL 261.76492 137.034195 \nL 262.984814 136.890141 \nL 263.594761 137.013678 \nL 264.204708 136.942158 \nL 265.424603 137.186665 \nL 266.03455 136.92273 \nL 266.644497 136.852346 \nL 267.254444 137.165135 \nL 267.864391 137.285254 \nL 268.474338 137.594881 \nL 269.694233 137.830403 \nL 270.30418 137.75858 \nL 270.914127 137.499199 \nL 272.134021 138.106268 \nL 273.353916 137.963104 \nL 274.57381 138.191015 \nL 275.183757 138.119816 \nL 275.793704 138.416293 \nL 277.013599 138.638976 \nL 277.623546 138.385247 \nL 278.233493 138.314504 \nL 279.453387 138.535237 \nL 280.063335 138.28468 \nL 281.283229 137.429837 \nL 281.893176 137.719923 \nL 282.503123 137.830403 \nL 283.11307 138.117752 \nL 283.723018 138.049527 \nL 284.332965 138.15818 \nL 284.942912 138.09022 \nL 285.552859 137.847123 \nL 286.772753 138.063142 \nL 287.382701 137.822119 \nL 287.992648 137.408809 \nL 288.602595 137.170873 \nL 289.212542 137.279545 \nL 289.822489 137.559821 \nL 291.652331 137.87921 \nL 292.872225 137.74951 \nL 293.482172 137.515739 \nL 294.092119 137.790174 \nL 294.702067 137.726077 \nL 295.312014 137.998495 \nL 296.531908 138.204629 \nL 297.141855 138.473649 \nL 298.971697 138.77591 \nL 299.581644 138.545548 \nL 300.191591 138.480986 \nL 300.801538 138.580948 \nL 301.411485 138.516623 \nL 302.021433 138.615979 \nL 302.63138 138.551901 \nL 303.851274 138.748889 \nL 304.461221 138.684962 \nL 305.681116 138.879791 \nL 306.291063 139.136919 \nL 306.90101 139.232705 \nL 307.510957 139.168362 \nL 308.730851 139.358334 \nL 309.950746 139.23031 \nL 310.560693 139.324439 \nL 311.17064 139.575375 \nL 311.780587 139.354414 \nL 312.390534 139.44754 \nL 313.000482 139.696317 \nL 314.830323 138.575741 \nL 316.050217 139.071487 \nL 316.660165 139.009879 \nL 317.270112 139.102039 \nL 319.7099 140.074274 \nL 321.539742 140.338569 \nL 322.149689 140.1247 \nL 322.759636 139.761646 \nL 323.979531 139.937653 \nL 325.199425 139.81441 \nL 325.809372 139.604763 \nL 326.419319 139.692313 \nL 327.029266 139.483935 \nL 327.639214 139.571361 \nL 328.249161 139.364223 \nL 328.859108 139.0113 \nL 329.469055 138.806406 \nL 330.079002 138.748519 \nL 330.688949 138.836627 \nL 331.298897 138.633542 \nL 332.518791 138.519606 \nL 333.128738 138.174228 \nL 333.738685 137.974485 \nL 334.95858 138.438258 \nL 335.568527 138.096166 \nL 336.178474 138.183961 \nL 337.398368 138.074077 \nL 338.008315 138.161333 \nL 339.838157 137.575481 \nL 340.448104 137.52249 \nL 341.058051 137.610001 \nL 341.667998 137.417217 \nL 342.277946 137.364926 \nL 342.887893 137.034195 \nL 344.107787 136.93197 \nL 344.717734 136.742774 \nL 345.327681 136.416266 \nL 345.937629 136.642481 \nL 346.547576 136.455132 \nL 347.157523 136.13136 \nL 347.76747 136.082856 \nL 350.207259 136.433971 \nL 350.817206 136.385344 \nL 351.427153 136.472107 \nL 352.0371 136.153798 \nL 352.647048 136.375299 \nL 353.256995 136.461532 \nL 355.086836 137.118497 \nL 355.696783 137.202448 \nL 356.306731 137.020201 \nL 356.916678 136.706068 \nL 357.526625 136.79036 \nL 358.136572 136.610101 \nL 358.746519 136.562412 \nL 359.356466 136.120282 \nL 361.186308 136.765838 \nL 361.796255 136.848795 \nL 363.016149 136.753814 \nL 364.236044 137.177226 \nL 365.455938 136.823914 \nL 366.065885 136.776953 \nL 366.675832 136.986903 \nL 367.28578 136.93981 \nL 368.505674 137.356518 \nL 369.725568 137.261594 \nL 369.725568 137.261594 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path clip-path=\"url(#pdf13762a40)\" d=\"M 65.361932 113.62558 \nL 65.971879 81.856751 \nL 66.581826 113.62558 \nL 67.80172 113.62558 \nL 68.411668 124.21519 \nL 69.021615 131.779197 \nL 69.631562 137.45221 \nL 70.241509 141.86454 \nL 70.851456 151.74818 \nL 72.071351 155.98402 \nL 72.681298 152.725679 \nL 73.291245 154.471219 \nL 73.901192 143.27649 \nL 74.511139 137.45221 \nL 75.121086 143.525655 \nL 76.340981 140.378287 \nL 76.950928 135.86376 \nL 77.560875 134.8048 \nL 78.170822 139.618264 \nL 78.780769 132.963133 \nL 79.390717 132.1574 \nL 80.000664 126.33311 \nL 80.610611 123.400605 \nL 81.220558 123.038573 \nL 81.830505 124.971596 \nL 82.440452 118.007491 \nL 83.0504 119.97935 \nL 85.490188 119.231844 \nL 86.100135 120.887033 \nL 86.710083 118.92039 \nL 87.32003 118.777284 \nL 88.539924 121.771434 \nL 90.369766 121.189587 \nL 90.979713 119.536065 \nL 92.199607 122.09727 \nL 92.809554 120.531846 \nL 93.419502 121.736772 \nL 94.639396 121.405701 \nL 95.249343 123.791608 \nL 95.85929 122.346436 \nL 96.469237 123.400605 \nL 97.079185 123.216171 \nL 97.689132 125.391817 \nL 98.299079 125.177881 \nL 99.518973 127.001929 \nL 100.12892 126.771301 \nL 100.738868 125.471583 \nL 101.348815 123.15623 \nL 101.958762 121.958386 \nL 102.568709 122.84879 \nL 103.178656 121.693855 \nL 103.788603 122.56057 \nL 104.398551 120.468099 \nL 105.008498 119.401736 \nL 106.228392 119.231844 \nL 107.448286 120.887033 \nL 108.058234 119.88986 \nL 109.278128 119.718236 \nL 109.888075 121.353135 \nL 110.498022 120.402932 \nL 111.107969 120.313755 \nL 111.717917 121.877228 \nL 112.327864 121.771434 \nL 112.937811 123.27687 \nL 113.547758 123.95045 \nL 114.157705 123.822985 \nL 115.3776 126.63932 \nL 116.597494 127.828122 \nL 117.207441 127.662974 \nL 117.817388 128.962256 \nL 118.427335 129.51 \nL 119.64723 129.15701 \nL 120.257177 129.684549 \nL 120.867124 129.51 \nL 121.477071 128.656 \nL 122.087018 129.172036 \nL 122.696966 128.339565 \nL 123.306913 129.51 \nL 123.91686 129.346244 \nL 124.526807 129.83417 \nL 125.136754 129.670442 \nL 125.746701 130.780756 \nL 126.966596 130.444373 \nL 127.576543 130.897958 \nL 128.18649 131.953756 \nL 128.796437 132.384326 \nL 129.406384 133.406172 \nL 132.45612 132.515162 \nL 133.066067 132.913806 \nL 133.676015 133.867672 \nL 134.285962 133.132759 \nL 134.895909 134.068135 \nL 135.505856 132.796433 \nL 136.115803 132.632573 \nL 138.555592 134.104662 \nL 139.165539 133.415999 \nL 139.775486 133.255103 \nL 140.385433 134.1216 \nL 140.995381 134.465936 \nL 142.825222 133.97749 \nL 143.435169 134.8048 \nL 144.655064 133.511416 \nL 145.265011 132.398073 \nL 145.874958 132.256926 \nL 146.484905 132.59205 \nL 147.094852 133.39286 \nL 147.704799 133.7147 \nL 148.314747 133.568062 \nL 149.534641 134.195326 \nL 150.754535 133.903556 \nL 151.364482 133.313311 \nL 151.97443 134.064272 \nL 152.584377 133.92234 \nL 153.194324 134.220549 \nL 153.804271 134.079487 \nL 155.024165 134.661703 \nL 155.634113 134.520519 \nL 156.24406 134.8048 \nL 157.463954 134.526133 \nL 158.073901 134.8048 \nL 158.683848 134.25469 \nL 159.293796 134.53152 \nL 159.903743 134.397512 \nL 161.123637 134.938846 \nL 161.733584 134.4052 \nL 162.343531 133.4811 \nL 162.953479 133.357772 \nL 164.173373 132.336058 \nL 166.613162 133.409769 \nL 167.223109 132.913806 \nL 167.833056 132.799671 \nL 168.443003 133.434386 \nL 169.05295 133.690103 \nL 169.662897 133.204052 \nL 170.272845 133.45815 \nL 170.882792 134.074488 \nL 171.492739 134.320709 \nL 172.712633 134.086863 \nL 173.32258 134.685818 \nL 173.932528 134.92312 \nL 174.542475 134.8048 \nL 175.152422 135.389866 \nL 175.762369 135.619386 \nL 176.982263 134.6897 \nL 178.202158 135.1464 \nL 179.422052 136.269325 \nL 181.251894 136.911633 \nL 181.861841 135.79758 \nL 182.471788 135.682697 \nL 183.691682 136.108144 \nL 184.301629 136.641781 \nL 184.911577 136.84747 \nL 185.521524 136.730192 \nL 186.131471 136.933372 \nL 188.57126 136.474105 \nL 189.181207 136.050637 \nL 189.791154 135.321366 \nL 190.401101 135.832923 \nL 192.230943 136.426179 \nL 192.84089 136.92273 \nL 193.450837 136.511191 \nL 194.060784 136.403238 \nL 194.670731 136.892897 \nL 197.720467 137.816523 \nL 198.330414 137.415938 \nL 198.940361 137.596613 \nL 200.770203 137.274129 \nL 201.38015 136.884906 \nL 201.990097 137.063924 \nL 203.209992 137.977022 \nL 203.819939 138.148892 \nL 204.429886 138.596712 \nL 205.039833 138.764397 \nL 205.64978 138.380514 \nL 206.259727 138.547687 \nL 206.869675 138.168027 \nL 207.479622 138.063142 \nL 208.089569 137.688783 \nL 208.699516 137.586824 \nL 209.91941 138.453321 \nL 210.529358 138.615288 \nL 211.139305 138.51117 \nL 211.749252 138.144262 \nL 212.359199 138.042947 \nL 213.579093 138.363604 \nL 214.189041 138.781307 \nL 214.798988 138.679054 \nL 215.408935 139.092098 \nL 217.238776 139.54895 \nL 219.678565 139.140706 \nL 220.288512 139.538981 \nL 220.898459 139.43776 \nL 221.508407 138.595633 \nL 222.728301 138.893453 \nL 223.338248 138.796275 \nL 223.948195 138.943273 \nL 224.558142 138.846644 \nL 225.778037 139.136919 \nL 226.387984 139.520178 \nL 226.997931 139.422829 \nL 227.607878 139.564175 \nL 228.217825 139.941554 \nL 228.827773 139.843722 \nL 229.43772 140.217267 \nL 230.047667 140.353604 \nL 230.657614 140.255337 \nL 231.267561 139.925051 \nL 233.097403 140.329821 \nL 234.927244 139.35947 \nL 236.147139 139.628537 \nL 237.367033 139.444776 \nL 237.97698 139.577581 \nL 238.586927 139.932408 \nL 239.196874 140.062581 \nL 239.806822 139.527695 \nL 240.416769 139.65837 \nL 241.026716 139.34844 \nL 241.636663 139.259745 \nL 242.24661 139.389995 \nL 242.856557 139.084164 \nL 243.466505 138.997278 \nL 244.076452 139.343204 \nL 244.686399 139.471409 \nL 245.296346 139.384096 \nL 245.906293 139.083435 \nL 247.126188 138.913146 \nL 247.736135 139.04065 \nL 248.956029 138.87234 \nL 249.565976 138.998707 \nL 250.175923 138.915248 \nL 250.785871 138.624008 \nL 252.005765 138.875076 \nL 252.615712 138.793094 \nL 253.225659 138.917274 \nL 253.835606 139.24561 \nL 254.445554 139.367527 \nL 255.055501 139.081381 \nL 256.885342 138.838937 \nL 257.495289 138.558083 \nL 258.105237 138.880302 \nL 259.325131 138.323612 \nL 259.935078 138.24643 \nL 262.374867 138.726885 \nL 262.984814 138.649647 \nL 263.594761 138.767786 \nL 264.204708 138.690898 \nL 264.814655 138.420771 \nL 265.424603 138.345407 \nL 266.03455 138.463035 \nL 266.644497 138.771905 \nL 267.254444 138.504789 \nL 267.864391 138.048467 \nL 269.084286 138.66132 \nL 269.694233 138.586809 \nL 270.30418 138.701275 \nL 270.914127 138.627085 \nL 274.57381 139.299236 \nL 275.183757 139.593146 \nL 275.793704 139.150827 \nL 276.403652 139.26037 \nL 277.013599 139.18671 \nL 277.623546 139.477582 \nL 278.233493 139.222186 \nL 278.84344 139.330281 \nL 280.063335 139.184646 \nL 280.673282 138.753471 \nL 281.283229 138.682689 \nL 281.893176 138.433827 \nL 282.503123 137.830403 \nL 283.11307 137.762793 \nL 283.723018 137.872544 \nL 284.332965 137.80519 \nL 284.942912 137.3862 \nL 286.772753 137.190376 \nL 287.382701 137.473967 \nL 287.992648 137.408809 \nL 288.602595 137.69026 \nL 289.212542 137.624866 \nL 290.432436 137.838583 \nL 291.042384 137.430803 \nL 292.262278 137.303157 \nL 292.872225 137.069964 \nL 293.482172 137.346312 \nL 294.092119 137.114236 \nL 294.702067 137.389002 \nL 295.312014 136.989961 \nL 295.921961 136.760669 \nL 296.531908 136.69979 \nL 297.141855 136.305691 \nL 297.751802 136.246318 \nL 298.36175 136.519049 \nL 298.971697 136.45943 \nL 300.191591 136.670326 \nL 300.801538 136.610783 \nL 301.411485 136.715299 \nL 302.021433 136.655945 \nL 302.63138 136.433971 \nL 303.241327 136.538146 \nL 303.851274 136.803861 \nL 304.461221 136.906559 \nL 305.071168 136.524948 \nL 305.681116 135.984409 \nL 306.291063 136.088394 \nL 306.90101 136.031815 \nL 307.510957 135.815872 \nL 308.120904 135.760258 \nL 309.340799 135.966752 \nL 309.950746 135.753128 \nL 310.560693 136.013542 \nL 311.780587 136.21675 \nL 312.390534 136.161108 \nL 313.000482 135.949624 \nL 313.610429 136.206373 \nL 314.830323 136.406154 \nL 315.44027 136.35073 \nL 316.050217 136.141358 \nL 317.270112 136.032582 \nL 317.880059 136.131691 \nL 319.7099 135.970169 \nL 320.319848 135.7652 \nL 320.929795 135.712483 \nL 321.539742 135.358177 \nL 322.149689 135.306681 \nL 322.759636 135.40563 \nL 323.369583 135.20441 \nL 323.979531 135.452638 \nL 324.589478 135.401398 \nL 325.199425 135.201607 \nL 325.809372 135.151191 \nL 326.419319 135.397232 \nL 327.029266 135.346598 \nL 327.639214 135.148786 \nL 330.688949 134.901959 \nL 331.298897 134.998664 \nL 331.908844 134.949867 \nL 332.518791 135.190757 \nL 333.128738 135.286146 \nL 333.738685 135.092954 \nL 334.348632 135.188135 \nL 334.95858 134.852613 \nL 335.568527 135.091013 \nL 336.178474 135.18555 \nL 336.788421 135.422132 \nL 337.398368 135.231232 \nL 339.838157 135.603129 \nL 341.667998 135.457911 \nL 342.277946 135.130636 \nL 342.887893 135.362154 \nL 343.49784 135.314587 \nL 345.327681 135.587517 \nL 345.937629 135.264218 \nL 347.76747 135.535122 \nL 348.377417 135.488 \nL 348.987365 135.304741 \nL 350.207259 135.212098 \nL 350.817206 135.30154 \nL 351.427153 135.120241 \nL 352.0371 135.209503 \nL 352.647048 135.433002 \nL 353.256995 135.386893 \nL 353.866942 135.206938 \nL 355.086836 135.383229 \nL 355.696783 135.337613 \nL 356.916678 135.512247 \nL 357.526625 135.33428 \nL 358.746519 135.507845 \nL 359.356466 135.725643 \nL 360.576361 135.896519 \nL 361.186308 135.45848 \nL 361.796255 135.283182 \nL 362.406202 135.369008 \nL 363.016149 135.194601 \nL 363.626097 135.150585 \nL 364.236044 135.365553 \nL 364.845991 135.192225 \nL 366.675832 135.061521 \nL 367.28578 135.2745 \nL 367.895727 134.847415 \nL 368.505674 135.059978 \nL 369.115621 134.889689 \nL 369.725568 134.974237 \nL 369.725568 134.974237 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#pdf13762a40)\" d=\"M 50.14375 134.593011 \nL 384.94375 134.593011 \n\" style=\"fill:none;stroke:#000000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 251.82 \nL 50.14375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 384.94375 251.82 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 251.82 \nL 384.94375 251.82 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 7.2 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 302.089063 103.26875 \nL 377.94375 103.26875 \nQ 379.94375 103.26875 379.94375 101.26875 \nL 379.94375 14.2 \nQ 379.94375 12.2 377.94375 12.2 \nL 302.089063 12.2 \nQ 300.089063 12.2 300.089063 14.2 \nL 300.089063 101.26875 \nQ 300.089063 103.26875 302.089063 103.26875 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 304.089063 20.298437 \nL 324.089063 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_23\"/>\n    <g id=\"text_17\">\n     <!-- P(die=1) -->\n     <defs>\n      <path d=\"M 19.671875 64.796875 \nL 19.671875 37.40625 \nL 32.078125 37.40625 \nQ 38.96875 37.40625 42.71875 40.96875 \nQ 46.484375 44.53125 46.484375 51.125 \nQ 46.484375 57.671875 42.71875 61.234375 \nQ 38.96875 64.796875 32.078125 64.796875 \nz\nM 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.34375 72.90625 50.609375 67.359375 \nQ 56.890625 61.8125 56.890625 51.125 \nQ 56.890625 40.328125 50.609375 34.8125 \nQ 44.34375 29.296875 32.078125 29.296875 \nL 19.671875 29.296875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-80\"/>\n      <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n     </defs>\n     <g transform=\"translate(332.089063 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 304.089063 34.976562 \nL 324.089063 34.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_25\"/>\n    <g id=\"text_18\">\n     <!-- P(die=2) -->\n     <g transform=\"translate(332.089063 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_26\">\n     <path d=\"M 304.089063 49.654687 \nL 324.089063 49.654687 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_27\"/>\n    <g id=\"text_19\">\n     <!-- P(die=3) -->\n     <g transform=\"translate(332.089063 53.154687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-51\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_28\">\n     <path d=\"M 304.089063 64.332812 \nL 324.089063 64.332812 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_29\"/>\n    <g id=\"text_20\">\n     <!-- P(die=4) -->\n     <g transform=\"translate(332.089063 67.832812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_30\">\n     <path d=\"M 304.089063 79.010937 \nL 324.089063 79.010937 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_31\"/>\n    <g id=\"text_21\">\n     <!-- P(die=5) -->\n     <g transform=\"translate(332.089063 82.510937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n    <g id=\"line2d_32\">\n     <path d=\"M 304.089063 93.689062 \nL 324.089063 93.689062 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_33\"/>\n    <g id=\"text_22\">\n     <!-- P(die=6) -->\n     <defs>\n      <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n     </defs>\n     <g transform=\"translate(332.089063 97.189062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.302734\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"99.316406\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"162.792969\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"252.099609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"335.888672\" xlink:href=\"#DejaVuSans-54\"/>\n      <use x=\"399.511719\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pdf13762a40\">\n   <rect height=\"244.62\" width=\"334.8\" x=\"50.14375\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPZ5pBAwzW2f"
      },
      "source": [
        "## 2.7 Documentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMkkGp9MzW2g",
        "outputId": "cd1fe7b4-7e92-42d6-acbc-a5dd84bacfdf"
      },
      "source": [
        "%%time\n",
        "print(dir(torch.distributions))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull']\n",
            "CPU times: user 103 µs, sys: 17 µs, total: 120 µs\n",
            "Wall time: 124 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GroxebTUzW2g",
        "outputId": "742f0405-feb8-4b0b-ab52-1d4216877d50"
      },
      "source": [
        "%%time\n",
        "help(torch.ones)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function ones:\n",
            "\n",
            "ones(...)\n",
            "    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
            "    \n",
            "    Returns a tensor filled with the scalar value `1`, with the shape defined\n",
            "    by the variable argument :attr:`size`.\n",
            "    \n",
            "    Args:\n",
            "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
            "            Can be a variable number of arguments or a collection like a list or tuple.\n",
            "    \n",
            "    Keyword arguments:\n",
            "        out (Tensor, optional): the output tensor.\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
            "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
            "            Default: ``torch.strided``.\n",
            "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            "            Default: if ``None``, uses the current device for the default tensor type\n",
            "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
            "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
            "        requires_grad (bool, optional): If autograd should record operations on the\n",
            "            returned tensor. Default: ``False``.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> torch.ones(2, 3)\n",
            "        tensor([[ 1.,  1.,  1.],\n",
            "                [ 1.,  1.,  1.]])\n",
            "    \n",
            "        >>> torch.ones(5)\n",
            "        tensor([ 1.,  1.,  1.,  1.,  1.])\n",
            "\n",
            "CPU times: user 721 µs, sys: 0 ns, total: 721 µs\n",
            "Wall time: 732 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX3QBlEvzW2h",
        "outputId": "f9b5dfcb-11a4-4197-92f7-d679daa91732"
      },
      "source": [
        "%%time\n",
        "torch.ones(4)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 554 µs, sys: 962 µs, total: 1.52 ms\n",
            "Wall time: 2.9 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    }
  ]
}